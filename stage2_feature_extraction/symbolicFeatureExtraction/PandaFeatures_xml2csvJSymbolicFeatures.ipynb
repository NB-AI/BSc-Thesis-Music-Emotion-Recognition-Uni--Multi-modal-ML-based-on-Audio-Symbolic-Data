{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we extract features by using knowledge from Panda et al 2018 and converting features of jSymbolic xml2csv. Furthermore, all features are then saved as in a 2D numpy array format (one row one sample, one column one feature) in a csv file. Feature names are stated as column titles there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for jSymbolic csv convertion:\n",
    "import xml.etree.ElementTree as Xet\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# for Panda et al 2018 feature extraction:\n",
    "import mido\n",
    "from mido import MidiFile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'sys' (built-in)> : \n",
      "your version  3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0] \n",
      "originally used version  3.7.3 \n",
      "\n",
      "<module 'pandas' from '/home/c/anaconda3/lib/python3.7/site-packages/pandas/__init__.py'> : \n",
      "your version  1.3.5 \n",
      "originally used version  1.3.5 \n",
      "\n",
      "<module 'mido' from '/home/c/anaconda3/lib/python3.7/site-packages/mido/__init__.py'> : \n",
      "your version  1.2.10 \n",
      "originally used version  1.2.10 \n",
      "\n",
      "<module 'numpy' from '/home/c/anaconda3/lib/python3.7/site-packages/numpy/__init__.py'> : \n",
      "your version  1.21.6 \n",
      "originally used version  1.21.6 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the used versions of imports:\n",
    "import sys\n",
    "import_list = [sys, pd, mido, np] # sys gives us the python version\n",
    "my_versions = ['3.7.3', '1.3.5','1.2.10','1.21.6']\n",
    "# When using MusicBERT you get an error for numpy versions >= 1.24!\n",
    "for ele, my_version in zip(import_list, my_versions):\n",
    "    try:\n",
    "        v = ele.__version__\n",
    "        print\n",
    "    except:\n",
    "        try:\n",
    "            v = ele.version\n",
    "            \n",
    "        except:\n",
    "            v = 'cant say version'\n",
    "    print(ele, ': \\nyour version ', v, '\\noriginally used version ', my_version, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features from Panda et al 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_names(arr, feature_name:str, one_row:dict):\n",
    "    \"\"\" When we want to store the feature values of Panda et al 2018 in a csv file we have to create\n",
    "    a dictionary containing the name for the individual feature (feature_name) we the related values \"\"\"\n",
    "    try: # array arr as input\n",
    "        for i,ele in enumerate(arr):\n",
    "\n",
    "            # Convert variable name into string:\n",
    "           # for  k, v in locals().items(): # search in local stack only activated in this function,\n",
    "            #    # is a dictionary with key=variable_name, value=variable_value\n",
    "              #  if np.all(v == arr):\n",
    "               #     feature_name_part_one = k\n",
    "                #    break\n",
    "\n",
    "\n",
    "\n",
    "            globals()[feature_name + str(i)] = ele # use globals() to store the vars in the global stack\n",
    "            # local() --> funktioniert nur innerhalb der Funktion\n",
    "            \n",
    "\n",
    "            one_row[feature_name+str(i)] = ele\n",
    "    except: # arr as scalar\n",
    "        one_row[feature_name] = arr\n",
    "    return one_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle midi files where each track has its own channel and midi files where all channels are in one track:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found out: velocity=0 with message type 'note_on' as alternative to 'note_off' (https://www.midi.org/forum/228-writing-midi-software-send-note-off,-or-zero-velocity-note-on)!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your version identical with original version \n",
      "-> numpy \n",
      "-> 1.21.6\n",
      "\n",
      "\n",
      "Your version identical with original version \n",
      "-> pandas \n",
      "-> 1.3.5\n",
      "\n",
      "\n",
      "Your version identical with original version \n",
      "-> mido \n",
      "-> 1.2.10\n",
      "\n",
      "\n",
      "Your version identical with original version \n",
      "-> sys \n",
      "-> 3.7.3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import basic_info_extraction as bie\n",
    "# import bie.basic_tools_panda, bie.channel_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panda et al., 2018, lines 389-391: The paper only considers the main track. However, there are samples where several tracks play an important role. Therefore, valuable information would get lost. To prevent this I created the arrays below. When you wish so, you can only consider a part of those arrays to get the main track, which should be the one with the most note entrances != 0.:<br><br>\n",
    "**note_collector_all** -> 2d array to collect ALL notes even when one track/channel has polyphonic structure. Rows build up the single tracks/channels, columns give us the note midi values. <br>\n",
    "**note_collector** -> Same as note_collector_all BUT only considers a monophonic structure per track/channel. So part of the polyphonic notes within one track/channel gets ignored.<br>\n",
    "**time_passed_ar** -> Refers to the note_collector. Gives us the time when which note starts with concerning the start at time 0. Through that we can compare different tracks/channels with different timings. Rows show us the single tracks/channels and columns the starting times of single notes findable in note_collector.<br>\n",
    "**time_passed_ar_end** -> Same as time_passed_ar but instead of counting the starting time of notes, here we compute the ending time of each note with origin time point 0.<br>\n",
    "**track_names** -> 1d array containing the names of individual tracks<br>\n",
    "**SAL** -> has the same row-column-structure as other arrays. Gives us the velocity/intensity median of each note. Assumes monophonic structure of single tracks.<br>\n",
    "**nd** -> Orientation at note_collector. How long each note lasts. <br>\n",
    "**CD** -> Orientation at note_collector. Do we have cresendo 'c', decresendo 'd' or non of both 'n' between notes?<br>\n",
    "**pause_collector** -> Orientation at note_collector. Getting the pauses between notes <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is correct: note_collector_all finds all notes which are played in the same time point. That shows us the code down there. c.mid has for the track 'Voice'/Alt exactly 26 notes which where played in the same moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(np.where(note_collector_all[4]!=-1)[0]) - len(np.where(note_collector[4]!=-1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding out features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basics. we have for each note $note_i$ of N notes:<br>\n",
    "respective sequence of $f_0$-s of frames of number $L_i$ -> One note i varies in the frequency -> $f_{j,i}$ where $j=1, ,L_i$ <br>\n",
    "MIDI note values (for each $f_0$) -> simply only use the f0 value for the current note i -> $midi_{j,i}$<br>\n",
    "MIDI note value for entire note -> simply the value of one note -> $MIDI_i$<br>\n",
    "sequence of pitch saliences -> $sal_{j,i}$<br>\n",
    "note duration in sec -> $nd_i$<br>\n",
    "starting time in sec -> $st_i$<br>\n",
    "ending time in sec -> $et_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.2 Melodic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2.1 MIDI Note Number (MNN) statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need: $MIDI_i$ which gives us the note value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def six_statistics(collecting_ar,output_1D=True):\n",
    "    ''' Gives us statistics, mean, std, skewness, kurtosis, max, min, for each channel/voice'''\n",
    "\n",
    "    MIDImean2, MIDIstd2, MIDIskew2, MIDIkurt2, MIDImax2, MIDImin2 = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    for line in collecting_ar:\n",
    "        \n",
    "        if output_1D == True:\n",
    "            line = collecting_ar.flatten()\n",
    "            note_collector_all_filtered = line[np.where(line!=-1)]\n",
    "        else: \n",
    "            note_entries_ind = np.where(line!=-1) # treats -1\n",
    "            note_collector_all_filtered = line[note_entries_ind]\n",
    "        \n",
    "        number_note_entries = len(note_collector_all_filtered)\n",
    "        line_mod = np.copy(line)\n",
    "        line_mod[np.where(line_mod==-1)] = 0\n",
    "\n",
    "        summed = np.sum(note_collector_all_filtered)\n",
    "        MIDImean_single = summed/number_note_entries\n",
    "        MIDImean2 = np.append(MIDImean2,MIDImean_single)\n",
    "\n",
    "        MIDIstd_single = (np.sum((note_collector_all_filtered - MIDImean_single)**2)/number_note_entries)**0.5\n",
    "        MIDIstd2 = np.append(MIDIstd2,MIDIstd_single)\n",
    "       \n",
    "        MIDIskew_single = np.sum((note_collector_all_filtered - MIDImean_single)**3)/((number_note_entries-1)*MIDIstd_single**3)\n",
    "        if np.isnan(MIDIskew_single):\n",
    "            MIDIskew_single = -1 \n",
    "        MIDIskew2 = np.append(MIDIskew2,MIDIskew_single)\n",
    "\n",
    "        MIDIkurt_single = number_note_entries * np.sum((note_collector_all_filtered - MIDImean_single)**4) / np.sum((note_collector_all_filtered - MIDImean_single**2)**2)\n",
    "        if np.isnan(MIDIkurt_single):\n",
    "            MIDIkurt_single = -1\n",
    "        MIDIkurt2 = np.append(MIDIkurt2,MIDIkurt_single)\n",
    "\n",
    "        try:\n",
    "            MIDImax_single = np.max(note_collector_all_filtered)\n",
    "        except: # we have no note in this track\n",
    "            MIDImax_single = -1\n",
    "        MIDImax2 = np.append(MIDImax2,MIDImax_single)\n",
    "\n",
    "        try:\n",
    "            MIDImin_single = np.min(note_collector_all_filtered)\n",
    "        except: # we have no note in this track\n",
    "            MIDImin_single = -1\n",
    "        MIDImin2 = np.append(MIDImin2,MIDImin_single)    \n",
    "        \n",
    "        if output_1D == True:\n",
    "            MIDImean2,MIDIstd2,MIDIskew2,MIDIkurt2 = MIDImean2[0],MIDIstd2[0],MIDIskew2[0],MIDIkurt2[0]\n",
    "            MIDImax2 = MIDImax2[0]\n",
    "            MIDImin2 = MIDImin2[0]\n",
    "            break\n",
    "        \n",
    "    return MIDImean2, MIDIstd2, MIDIskew2, MIDIkurt2, MIDImax2, MIDImin2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> MIDImean**<br>\n",
    "Let's take all the note values of note_collector_all. Add up all note values and then divide by their numbers. Make that for all tracks at once/whole piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note_entries_ind = np.where(note_collector_all!=-1)\n",
    "# note_collector_all_filtered = note_collector_all[note_entries_ind]\n",
    "# number_note_entries = len(note_collector_all_filtered)\n",
    "# summed = np.sum(note_collector_all_filtered)\n",
    "# MIDImean = summed/number_note_entries\n",
    "# MIDImean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><p style=\"color:red;\">MIDImean already used in jSymbolic \"Mean Pitch\"</p></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each track get its own mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDImean2, MIDIstd2, MIDIskew2, MIDIkurt2, MIDImax2, MIDImin2 = six_statistics()\n",
    "# MIDImean2[mask_over_voices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> MIDIstd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDIstd = (np.sum((note_collector_all_filtered - MIDImean)**2)/number_note_entries)**0.5\n",
    "# MIDIstd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><p style=\"color:red;\">MIDIstd already used in jSymbolic \"Pitch Variability\"</p></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDIstd2[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> MIDIskew**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDIskew = np.sum((note_collector_all_filtered - MIDImean)**3)/((number_note_entries-1)*MIDIstd**3)\n",
    "# MIDIskew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><p style=\"color:red;\">MIDIskew already used in jSymbolic \"Pitch Skewness\"</p></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDIskew2[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> MIDIkurt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDIkurt = number_note_entries * np.sum((note_collector_all_filtered - MIDImean)**4) / np.sum((note_collector_all_filtered - MIDImean**2)**2)\n",
    "# MIDIkurt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><p style=\"color:red;\">MIDIkurt already used in jSymbolic \"Pitch Kurtosis\"</p></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDIkurt2[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> MIDImax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDImax = np.max(note_collector_all_filtered)\n",
    "# MIDImax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDImax2[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> MIDImin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MIDImin = np.min(note_collector_all_filtered)\n",
    "# MIDImin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDImin2[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2.2 Note Space Length (NSL), Chroma NSL (CNSL) -> Not in featrues.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2.3 Register Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"This class of features indicates how the notes of the predominant melody are distributed across different pitch ranges.\"<br>\n",
    "Use https://computermusicresource.com/midikeys.html to find out different pitch range values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RD(lower_border, upper_border, note_ar):\n",
    "    '''Considers each track/channel extra. Else it wouldnt make sense to get the pitched range of different\n",
    "    pitch ranged tracks.'''\n",
    "    RD_arr = np.array([])\n",
    "    #for track in note_collector: # error seen at 11102022\n",
    "    for track in note_ar:  \n",
    "        #summed = np.sum(track[np.where((track>=lower_border) & (track<=upper_border))])\n",
    "        valid = len(np.where((track>=lower_border) & (track<=upper_border))[0])\n",
    "        N = len(np.where(track>-1)[0])\n",
    "        rd = valid/N\n",
    "        RD_arr = np.append(RD_arr, rd)\n",
    "    return RD_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RD_1D(lower_border, upper_border, note_ar):\n",
    "    '''Considers each track/channel extra. Else it wouldnt make sense to get the pitched range of different\n",
    "    pitch ranged tracks.'''\n",
    "    \n",
    "    a = note_ar.flatten()\n",
    "    notes_cleaned = a[np.where(a!=-1)]\n",
    "    valid = len(np.where((notes_cleaned>=lower_border) & (notes_cleaned<=upper_border))[0])\n",
    "    N = len(notes_cleaned)\n",
    "    return valid/N\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> RDsoprano**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDsoprano = RD(72,96,note_collector_all)\n",
    "# RDsoprano[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> RDmezzosoprano**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDmezzosoprano = RD(69,93,note_collector_all)\n",
    "# RDmezzosoprano[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> RDcontralto**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDcontralto = RD(65,88,note_collector_all)\n",
    "# RDcontralto[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> RDtenor**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDtenor = RD(59,81,note_collector_all)\n",
    "# RDtenor[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> RDbaritone**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDbaritone = RD(55,77,note_collector_all)\n",
    "# RDbaritone[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> RDbass**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RDbass = RD(52,76,note_collector_all)\n",
    "# RDbass[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2.4 Register Distribution per Second -> Not in features.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2.5 Ratios of Pitch Transitions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes are followed by higher/lower/same note -> melody contour/movement -> Is melody smooth/conjunct or disjunct?<br>\n",
    "Here it makes sense to look at note_collector because here we have monophonic track note approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratios_of_transition_NS(ar, nd_usage):\n",
    "    note_collector_mod = np.copy(ar)\n",
    "    note_collector_mod[np.where(note_collector_mod==-1)] = float('nan')\n",
    "    if nd_usage == False:\n",
    "        spec_diff = (note_collector_mod[:,:-1] - note_collector_mod[:,1:])\n",
    "    else:\n",
    "        spec_diff = (note_collector_mod[:,:-1] / note_collector_mod[:,1:]) - 1\n",
    "        \n",
    "    \n",
    "    THPNR, TLPNR, TEPNR = np.array([]),np.array([]),np.array([])\n",
    "\n",
    "    NSmean, NSstd, NSskew, NSkurt, NSmax, NSmin =  np.array([]),np.array([]),np.array([]),np.array([]),np.array([]),np.array([])\n",
    "\n",
    "    for line in spec_diff:\n",
    "        if nd_usage==False:\n",
    "            equal_ind = np.where(line==0)[0]\n",
    "            lower_ind = np.where(line>0)[0]\n",
    "            higher_ind = np.where(line<0)[0]\n",
    "        else:\n",
    "            equal_ind = np.where((line<0.1)&(line>-0.1))[0]\n",
    "            lower_ind = np.where(line<-0.1)[0]\n",
    "            higher_ind = np.where(line>0.1)[0]\n",
    "            \n",
    "        line_mod = line[~np.isnan(line)] # treats nan\n",
    "        N = len(line_mod) # remove nan\n",
    "        THPNR_single, TLPNR_single, TEPNR_single = len(higher_ind)/(N-1),len(lower_ind)/(N-1),len(equal_ind)/(N-1)\n",
    "        THPNR = np.append(THPNR, THPNR_single)\n",
    "        TLPNR = np.append(TLPNR, TLPNR_single)\n",
    "        TEPNR = np.append(TEPNR, TEPNR_single)\n",
    "\n",
    "        line_abs = abs(line_mod)\n",
    "        NSmean_single = sum(line_abs)/(N-1)\n",
    "        NSmean = np.append(NSmean, NSmean_single)\n",
    "\n",
    "        NSstd_single = (np.sum((line_abs - NSmean_single)**2)/N)**0.5\n",
    "        NSstd = np.append(NSstd, NSstd_single)\n",
    "\n",
    "        NSskew_single = np.sum((line_abs - NSmean_single)**3)/((N-1)*NSstd_single**3)\n",
    "        NSskew = np.append(NSskew, NSskew_single)\n",
    "\n",
    "        NSkurt_single = N * np.sum((line_abs - NSmean_single)**4) / np.sum((line_abs - NSmean_single**2)**2)\n",
    "        NSkurt = np.append(NSkurt, NSkurt_single)\n",
    "\n",
    "        try:\n",
    "            NSmax_single = np.max(line_abs)\n",
    "        except: # We dont have a single note in this track\n",
    "            NSmax_single = -1\n",
    "        NSmax = np.append(NSmax, NSmax_single)\n",
    "\n",
    "        try:\n",
    "            NSmin_single = np.min(line_abs)\n",
    "        except: # We dont have a single note in this track\n",
    "            NSmin_single = -1\n",
    "        NSmin = np.append(NSmin, NSmin_single)\n",
    "\n",
    "    return NSmean, NSstd, NSskew, NSkurt, NSmax, NSmin, THPNR, TLPNR, TEPNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratios_of_transition_NS_1D(ar, nd_usage=False):\n",
    "    '''if usage then THPNR\n",
    "        elif no usage NSmean'''\n",
    "    note_collector_mod = np.copy(ar)\n",
    "    note_collector_mod[np.where(note_collector_mod==-1)] = float('nan')\n",
    "    if nd_usage == False:\n",
    "        spec_diff = (note_collector_mod[:,:-1] - note_collector_mod[:,1:])\n",
    "    else:\n",
    "        spec_diff = (note_collector_mod[:,:-1] / note_collector_mod[:,1:]) - 1\n",
    "        \n",
    "    \n",
    "    THPNR, TLPNR, TEPNR = 0,0,0#np.array([]),np.array([]),np.array([])\n",
    "\n",
    "    NSmean, NSstd, NSskew, NSkurt, NSmax, NSmin =  np.array([]),np.array([]),np.array([]),np.array([]),np.array([]),np.array([])\n",
    "    total_note_number_N = -1\n",
    "    all_values_abs = []\n",
    "    NS_part = 0\n",
    "    for line in spec_diff:\n",
    "        if nd_usage==False:\n",
    "            equal_ind = np.where(line==0)[0]\n",
    "            lower_ind = np.where(line>0)[0]\n",
    "            higher_ind = np.where(line<0)[0]\n",
    "        else:\n",
    "            equal_ind = np.where((line<0.1)&(line>-0.1))[0]\n",
    "            lower_ind = np.where(line<-0.1)[0]\n",
    "            higher_ind = np.where(line>0.1)[0]\n",
    "            \n",
    "        line_mod = line[~np.isnan(line)] # treats nan\n",
    "        N = len(line_mod) # remove nan\n",
    "        total_note_number_N += N \n",
    " \n",
    "        THPNR += len(higher_ind)\n",
    "        TLPNR += len(lower_ind)\n",
    "        TEPNR += len(equal_ind)\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "\n",
    "        line_abs = abs(line_mod)\n",
    "        NS_part += sum(line_abs)\n",
    "        \n",
    "        all_values_abs.extend(line_abs)\n",
    "        \n",
    "        \n",
    "       \n",
    "\n",
    "    NSmean = NS_part/total_note_number_N\n",
    "    NSstd = (np.sum((np.asarray(all_values_abs)- NSmean)**2)/total_note_number_N)**0.5\n",
    "    NSskew = np.sum((np.asarray(all_values_abs) - NSmean)**3)/((total_note_number_N)*NSstd**3)\n",
    "    NSkurt = total_note_number_N * np.sum((np.asarray(all_values_abs) - NSmean)**4) / np.sum((np.asarray(all_values_abs) - NSmean**2)**2)\n",
    "    \n",
    "    NSmin = min(all_values_abs)\n",
    "    NSmax = max(all_values_abs)\n",
    "    \n",
    "    \n",
    "    return NSmean, NSstd, NSskew, NSkurt, NSmax, NSmin, THPNR/total_note_number_N, TLPNR/total_note_number_N, TEPNR/total_note_number_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSmean, NSstd, NSskew, NSkurt, NSmax, NSmin, THPNR, TLPNR, TEPNR = ratios_of_transition_NS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> Transitions to Higher Pitch Notes Ratio (THPNR)**<br>\n",
    "Each track/channel gets extra entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THPNR[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> Transitions to Lower Pitch Notes Ratio (TLPNR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TLPNR[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> Transitions to Equal Pitch Notes Ratio (TEPNR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEPNR[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2.6 Note Smoothness (NS) statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoothness means how close consecutive notes are. Take note_collector again because we look at a sequence and not a polyphonic happening.<br>\n",
    "Compute the 6 statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> NSmean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSmean[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> NSstd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSstd[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> NSskew**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSskew[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> NSkurt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSkurt[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> NSmax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSmax[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> NSmin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSmin[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.3 Dynamics Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3.0 Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3.1 Note Intensity (NI) statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the 6 statistics based on median pitch salience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALmean2, SALstd2, SALskew2, SALkurt2, SALmax2, SALmin2 = six_statistics(SAL)\n",
    "# SALmean2[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3.2 Note Intensity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_intensity_distribution(note_ar, mean, std,output_1D=False):\n",
    "    '''Considers each track/channel extra. Else it wouldnt make sense to get the pitched range of different\n",
    "    pitch ranged tracks.'''\n",
    "    \n",
    "    LINR, MINR, HINR = np.array([]),np.array([]),np.array([])\n",
    "    for ind, track in enumerate(note_ar):\n",
    "        \n",
    "        if output_1D==True:\n",
    "            track = note_ar\n",
    "            mean2 = mean\n",
    "            std2 = std\n",
    "        else:\n",
    "            mean2 = mean[ind]\n",
    "            std2 = std[ind]\n",
    "        \n",
    "        low_ind = len(np.where((track<=mean2-0.5*std2) & (track>-1) ) [0])\n",
    "        medium_ind = len(np.where((track>mean2-0.5*std2)&(track<mean2+0.5*std2) & (track>-1) )[0])\n",
    "        high_ind = len(np.where((track>=mean2+0.5*std2) & (track>-1) )[0])\n",
    "        \n",
    "        N = len(np.where(track>-1))\n",
    "        \n",
    "        LINR_single = low_ind/N\n",
    "        LINR = np.append(LINR, LINR_single)\n",
    "        \n",
    "        MINR_single = medium_ind/N\n",
    "        MINR = np.append(MINR, MINR_single)\n",
    "        \n",
    "        HINR_single = high_ind/N\n",
    "        HINR = np.append(HINR, HINR_single)\n",
    "        \n",
    "        if output_1D==True:\n",
    "            LINR,MINR,HINR = LINR[0],MINR[0],HINR[0]\n",
    "            break\n",
    "        \n",
    "        \n",
    "    return LINR, MINR, HINR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINR, MINR, HINR = note_intensity_distribution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3.3 Note Intensity Distribution per Second -> not in features.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3.4 Ratios of Note Intensity Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b,c,d,e,f, THINR, TLINR, TELNR =ratios_of_transition_NS(SAL)\n",
    "# TELNR[mask_over_voices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3.5 Crescendo, Decresendo (CD) statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = np.zeros((CD.shape))\n",
    "# D[np.where(CD=='d')] = 1\n",
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = np.zeros((CD.shape))\n",
    "# C[np.where(CD=='c')] = 1\n",
    "# C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CD_seq_finder(ar):\n",
    "    s2 = np.array([[0]*ar.shape[0]]).reshape((ar.shape[0],1))\n",
    "    D = np.append(ar, s2,axis=1)\n",
    "    D = np.append(s2,D,axis=1)\n",
    "    D_spec_diff = D[:,:-1]-D[:,1:]\n",
    "\n",
    "    number_arr = np.array([])\n",
    "    len_arr = np.zeros((D.shape))-1\n",
    "\n",
    "    first_round = True\n",
    "    for ind, track in enumerate(D_spec_diff):\n",
    "\n",
    "\n",
    "        end_seq = np.where(track==1)[0]\n",
    "        start_seq = np.where(track==-1)[0]\n",
    "\n",
    "        number = len(start_seq)\n",
    "        number_arr = np.append(number_arr, number)\n",
    "        \n",
    "        len_seq = end_seq - start_seq + 1 # error corrected at 11102022\n",
    "        len_arr[ind, :number] = len_seq\n",
    "    \n",
    "    return len_arr, number_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_seq_C, number_seq_C = CD_seq_finder(ar=C)\n",
    "# print(number_seq_C[mask_over_voices])\n",
    "# Cmean2, Cstd2, Cskew2, Ckurt2, Cmax2, Cmin2 = six_statistics(len_seq_C)\n",
    "\n",
    "# len_seq_D, number_seq_D = CD_seq_finder(ar=D)\n",
    "# Dmean2, Dstd2, Dskew2, Dkurt2, Dmax2, Dmin2 = six_statistics(len_seq_D)\n",
    "# print(number_seq_D[mask_over_voices])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.4 Rhythmic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4.1 Note Duration (ND) statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndmean2, ndstd2, ndskew2, ndkurt2, ndmax2, ndmin2  = six_statistics(nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4.2 Note Duration Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR, MLNR, LNR = note_intensity_distribution(note_ar=nd, mean=ndmean2, std=ndstd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4.3 Note Duration Distribution per Second -> Not in features.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4.4 Ratios of Note Duration transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b,c,d,e,f, TLNR,TSNR,TELNR = ratios_of_transition_NS(nd, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.5 Musical Texture Features -> Based on F0 estimates not MIDI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.5.1  Musical Layers (ML) statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.5.2 Musical Layers Distribution (MLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.5.3  Ratio of Musical Layers Transitions (RMLT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.6 Expressivity Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.6.1 Articulation Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Staccato (short, strong notes), Legato (smoothly connected notes). The program MuseScore for MIDI visualization and playing is setting the features by its own rules, so it is not written down in the messages (https://musescore.org/en/node/323749). One possibility to get legato: midi message control_change control=68, value<=63 (turns legato off) else on (https://anotherproducer.com/online-tools-for-musicians/midi-cc-list/). However, MuseScore is connecting notes without this control change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 1:\n",
    "def articulation_detection(time_passed_ar, pause_collector, nd, output_1D=False):\n",
    "\n",
    "    time_passed_ar_mod = np.copy(time_passed_ar)\n",
    "    time_passed_ar_mod[np.where(time_passed_ar_mod==-1)] = float('nan')\n",
    "    IOI = (time_passed_ar_mod[:,1:]-time_passed_ar_mod[:,:-1]) # nd + next_note_start.time = this_note_end + next_note_start.time\n",
    "    IOI[np.where(IOI==0)] = 0.0000000000000000000000001 # so we get value 0 for ratio when / IOI instead of nan\n",
    "    INS = np.copy(pause_collector[:,1:]) # pause at start not interesting here but the pauses BETWEEN notes\n",
    "    INS[np.where(INS==-1)] = float('nan')\n",
    "    ratio = INS/IOI\n",
    "\n",
    "    # --> We ignore the nd's the last note because we look here always to the relation between two nodes\n",
    "    # such that the ratio array becomes smaller than the nd array\n",
    "\n",
    "    art = (np.zeros((ratio.shape))+float('nan'))\n",
    "\n",
    "    #for ind, track in enumerate(art):\n",
    "    art[np.where(INS <= 0.48)] = 1 # Legato\n",
    "    art[np.where((ratio>=0.25)&(ratio<=0.75)&(nd[:,:-1]<=24))] = 2  # Staccato # this staccto fits to the first\n",
    "    # appearing staccato in MuseScore\n",
    "    art[np.where((art!=1)&(art!=2)&(~np.isnan(ratio)))] = 0 # Rest # error removed 12102022\n",
    "    \n",
    "    if output_1D == True: # Make art 1D\n",
    "    \n",
    "        art = art.flatten()\n",
    "        art = art[np.where(~np.isnan(art))]\n",
    "\n",
    "    return art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.1.1 Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def art_ratios(ar, nd):\n",
    "    SR, LR, OTR = np.array([]), np.array([]), np.array([])\n",
    "    SNDR, LNDR, OTNDR =  np.array([]), np.array([]), np.array([])\n",
    "    nd_S = np.zeros((nd.shape)) -1 #+ float('nan')\n",
    "    nd_L, nd_OT = np.copy(nd_S), np.copy(nd_S)\n",
    "    track_ind = 0\n",
    "    \n",
    "    for line, nd_line in zip(ar, nd):\n",
    "        \n",
    "        nd_line_mod = nd_line[np.where(nd_line!=-1)]\n",
    "        line_mod = line[~np.isnan(line)]\n",
    "        \n",
    "        ind_legato = np.where(line_mod==1)\n",
    "        number_legato = len(ind_legato[0])\n",
    "        LNDR_single = np.sum(nd_line_mod[ind_legato])\n",
    "        nd_L[track_ind, ind_legato[0]] = nd_line_mod[ind_legato]\n",
    "\n",
    "        ind_staccato = np.where(line_mod==2)\n",
    "        number_staccato = len(ind_staccato[0])\n",
    "        SNDR_single = np.sum(nd_line_mod[ind_staccato])\n",
    "        nd_S[track_ind, ind_staccato[0]] = nd_line_mod[ind_staccato]\n",
    "        \n",
    "        ind_rest = np.where(line_mod==0)\n",
    "        number_rest = len(ind_rest[0])\n",
    "        OTNDR_single = np.sum(nd_line_mod[ind_rest])\n",
    "        nd_OT[track_ind, ind_rest[0]] = nd_line_mod[ind_rest]\n",
    "        \n",
    "        all_notes = len(line_mod)\n",
    "        whole_duration = np.sum(nd_line_mod)\n",
    "        \n",
    "        if all_notes == 0:\n",
    "            all_notes=1 # because below we don't want to devide by 0:\n",
    "            whole_duration = 1\n",
    "            \n",
    "        SR = np.append(SR, number_staccato/all_notes)\n",
    "        LR = np.append(LR, number_legato/all_notes)\n",
    "        OTR = np.append(OTR, number_rest/all_notes)\n",
    "        \n",
    "        SNDR = np.append(SNDR, SNDR_single/whole_duration)\n",
    "        LNDR = np.append(LNDR, LNDR_single/whole_duration)\n",
    "        OTNDR = np.append(OTNDR, OTNDR_single/whole_duration)        \n",
    "        \n",
    "        track_ind += 1 \n",
    "        \n",
    "    return SR, LR, OTR, SNDR, LNDR, OTNDR, nd_S, nd_L, nd_OT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> Staccato Ratio (SR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SR, LR, OTR, SNDR, LNDR, OTNDR, nd_S, nd_L, nd_OT = art_ratios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> Legato Ratio (LR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> Other Transistions Ratio (OTR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.1.2 Note ratios statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> Staccato Notes Duration Ratio (SNDR) statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd_Smean2, nd_Sstd2, nd_Sskew2, nd_Skurt2, nd_Smax2, nd_Smin2 = six_statistics(nd_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> Legato Notes Duration Ratio (LNDR) statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nd_Lmean2, nd_Lstd2, nd_Lskew2, nd_Lkurt2, nd_Lmax2, nd_Lmin2 = six_statistics(nd_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-> Other Transition Notes Duration Ratio (OTNDR) statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nd_OTmean2, nd_OTstd2, nd_OTskew2, nd_OTkurt2, nd_OTmax2, nd_OTmin2 = six_statistics(nd_OT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.6.2 Glissando Features -> f0 estimates, MIDI files not directly usable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About using midi: Die exakte Notation eines Glissandos nur durch Noten ist nicht möglich, da ein ideales Glissando eine stetige Veränderung der Tonfrequenz ist, Noten jedoch diskrete Tonhöhen bezeichnen (https://de.wikipedia.org/wiki/Glissando). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imitate glissando with help of pitch wheel: https://music.tutsplus.com/tutorials/imitate-guitar-techniques-with-midi-part-3-glissando-1-octave--audio-7299"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.2.1 Glissando Presence (GP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.2.2 Glissando Extent (GE) statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.2.3 Glissando Duration (GD) and Glissando Slope (GS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.2.4 Glissando Coverage (GC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.2.5 Glissando Direction (GDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.2.6 Glissando to Non-Glissando Ratio (GNGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.6.3 Vibrato and Tremolo Features -> MIDI not fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason MIDI not suited for that task: \"Unfortunately, the general MIDI implementation of modulation has one parameter which corresponds somewhat to width of the vibrato.  It is up to the synthesizer playing the file to create the vibrato.  Unfortunately, the modulation MIDI event is limited in type of vibrato it can create.  It has a limited range of control.\" (http://www-classes.usc.edu/engr/ise/599muscog/2004/projects/yang/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tremolo: like vibrato but regarding to change in amplitude and **using pitch saliences of each note** instead of f0 variation. However, we only have two velocity/intensity/salience values per note which change in c.mid always in same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.3.1 Vibrato Presence (VP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.3.2 Vibrato Rate (VR) statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.3.3 Vibrato Coverage (VC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.3.4 High-Frequency Virbrato Coverage (HFVC) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.3.5 Vibrato to Non-Vibrato Ratio (VNVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.6.3.6 Vibrato Notes Base Frequency (VNBF) statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.7 Voice Analysis Toolbox (VAT) Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.7.1 All features of 3.4.... only using single voice instead of instruments --> Makes no sense for midi without singing voice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><p style=\"color:red;\">Make the steps again only with other audio file (only singing voice). Separate the voice from the mixed file. Panda et al. 2018 used Fan et al. approach, I for myself downloaded an other one which worked out well in samples.</p></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.7.2 Voice quality toolkit analysis directly from audio file -> not MIDI related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xml2csv convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_feature_values_one_sample_xml(ele, one_row,first_file_loop,cols):\n",
    "    for i in ele.findall('feature'): # go through each feature per sample\n",
    "\n",
    "                value_one_feat = [float(i.text.replace(\",\",\".\")) for i in i.findall(\"v\")]\n",
    "\n",
    "                if len(value_one_feat) == 1:\n",
    "                    value_one_feat = value_one_feat[0]\n",
    "                elif len(value_one_feat) == 0:\n",
    "                    value_one_feat = -1 \n",
    "\n",
    "                name = i.find(\"name\").text\n",
    "\n",
    "                if first_file_loop == True:\n",
    "                    cols.append(name)\n",
    "\n",
    "                one_row[f\"{name}\"] = value_one_feat\n",
    "    return one_row, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting Feature extraction from Panda et al 2018 and xml2csv convertion together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(aim_storage_path_file,xml_path_file,midi_path, source_id): \n",
    "    '''aim_storage_path_file,xml_path_file: path + file name;\n",
    "    midi_path: only path of stored midi files;\n",
    "    source_id: kind of label telling us how the beloning midi file was generated'''\n",
    "\n",
    "\n",
    "    try:\n",
    "        aimed_directory = os.mkdir(aim_storage_path_file.split('/')[0])\n",
    "    except:\n",
    "        aimed_directory = aim_storage_path_file.split('/')[0]\n",
    "\n",
    "    cols = [\"sample_id\",\"source_id\"]\n",
    "    rows = []\n",
    "    first_file_loop = True\n",
    "\n",
    "    xmlparse = Xet.parse(xml_path_file) \n",
    "    root = xmlparse.getroot()\n",
    "\n",
    "    if 'feature_vector_file' in str(root): # sort of file saving features\n",
    "        base = root.findall(\"data_set\") # sample list\n",
    "\n",
    "        for ind_base, ele in enumerate(base): # go through each sample\n",
    "            file_path = base[ind_base].find(\"data_set_id\").text\n",
    "            file_name = file_path.split('/')[-1].split('.')[0]\n",
    "            print('current file:', file_name)\n",
    "\n",
    "            ###################################################################\n",
    "            \n",
    "            # xml2csv convertion of jSymboic features:\n",
    "\n",
    "            one_row,cols = getting_feature_values_one_sample_xml(ele, {\"sample_id\": file_name, \"source_id\": source_id},first_file_loop,cols)\n",
    "            # fill this row with all features of our current sample \n",
    "\n",
    "            print(f'done: convertion jSymbolic xml feature file into csv for {file_name}')\n",
    "            \n",
    "            ###################################################################\n",
    "            \n",
    "            # Extracting the Panda et al features and saving them in the final csv dictionary\n",
    "            # together with the jSymbolic features:\n",
    "\n",
    "            # basic tools for feature extraction:\n",
    "\n",
    "            pause_collector, nd, note_collector, note_collector_all,SAL,CD,time_passed_ar, nd_short, _ = bie.basic_tools_panda(midi_path, file_name)\n",
    "            mask = bie.channel_mask(note_collector) # mask to get only relevant channels/voices\n",
    "\n",
    "\n",
    "            # feature: Statistics which are not covered by jSymbolic and refering to ALL note of the whole sample:\n",
    "\n",
    "            note_entries_ind = np.where(note_collector_all!=-1)\n",
    "            note_collector_all_filtered = note_collector_all[note_entries_ind]\n",
    "            MIDImax = np.max(note_collector_all_filtered)\n",
    "            MIDImin = np.min(note_collector_all_filtered)\n",
    "\n",
    "            one_row['MIDImax'] = MIDImax\n",
    "            one_row['MIDImin'] = MIDImin\n",
    "\n",
    "            # feature: Register Distribution:\n",
    "\n",
    "            RDsoprano = RD_1D(72,96,note_collector_all)\n",
    "            RDmezzosoprano = RD_1D(69,93,note_collector_all)\n",
    "            RDcontralto = RD_1D(65,88,note_collector_all)\n",
    "            RDtenor = RD_1D(59,81,note_collector_all)\n",
    "            RDbaritone = RD_1D(55,77,note_collector_all)\n",
    "            RDbass = RD_1D(52,76,note_collector_all)\n",
    "\n",
    "            one_row = create_feature_names(RDsoprano, 'RDsoprano', one_row)\n",
    "            one_row = create_feature_names(RDmezzosoprano, 'RDmezzosoprano', one_row)\n",
    "            one_row = create_feature_names(RDcontralto, 'RDcontralto', one_row)\n",
    "            one_row = create_feature_names(RDtenor, 'RDtenor', one_row)\n",
    "            one_row = create_feature_names(RDbaritone, 'RDbaritone', one_row)\n",
    "            one_row = create_feature_names(RDbass, 'RDbass', one_row)    \n",
    "\n",
    "\n",
    "            # feature: Ratio of Pitch Transitions +  Note smoothness statistics:\n",
    "\n",
    "            a,b,c,d,e,f, THPNR, TLPNR, TEPNR = ratios_of_transition_NS_1D(note_collector,True)\n",
    "\n",
    "            one_row = create_feature_names(THPNR, 'THPNR', one_row)\n",
    "            one_row = create_feature_names(TLPNR, 'TLPNR', one_row)\n",
    "            one_row = create_feature_names(TEPNR, 'TEPNR', one_row)\n",
    "\n",
    "            NSmean, NSstd, NSskew, NSkurt, NSmax, NSmin, a,b,c = ratios_of_transition_NS_1D(note_collector,False)\n",
    "\n",
    "            one_row = create_feature_names(NSmean, 'NSmean', one_row)\n",
    "            one_row = create_feature_names(NSstd, 'NSstd', one_row)\n",
    "            one_row = create_feature_names(NSskew, 'NSskew', one_row)\n",
    "            one_row = create_feature_names(NSkurt, 'NSkurt', one_row)\n",
    "            one_row = create_feature_names(NSmax, 'NSmax', one_row)\n",
    "            one_row = create_feature_names(NSmin, 'NSmin', one_row) \n",
    "\n",
    "\n",
    "            # feature: Note intensity statistics:\n",
    "\n",
    "            SALmean2, SALstd2, SALskew2, SALkurt2, SALmax2, SALmin2 = six_statistics(SAL,True)\n",
    "\n",
    "            one_row = create_feature_names(SALmean2, 'SALmean', one_row)\n",
    "            one_row = create_feature_names(SALstd2, 'SALstd', one_row)\n",
    "            one_row = create_feature_names(SALskew2, 'SALskew', one_row)\n",
    "            one_row = create_feature_names(SALkurt2, 'SALkurt', one_row)\n",
    "            one_row = create_feature_names(SALmax2, 'SALmax', one_row)\n",
    "            one_row = create_feature_names(SALmin2, 'SALmin', one_row) \n",
    "\n",
    "\n",
    "            # feature: Note intensity distribution:\n",
    "\n",
    "            LINR, MINR, HINR = note_intensity_distribution(SAL, SALmean2, SALstd2,True)\n",
    "\n",
    "            one_row = create_feature_names(LINR, 'LINR', one_row)\n",
    "            one_row = create_feature_names(MINR, 'MINR', one_row)\n",
    "            one_row = create_feature_names(HINR, 'HINR', one_row)\n",
    "\n",
    "\n",
    "            # feature: Ratios of Note Intensity Transitions:\n",
    "\n",
    "            a,b,c,d,e,f, THINR, TLINR, TELNR = ratios_of_transition_NS_1D(SAL, True)\n",
    "\n",
    "            one_row = create_feature_names(THINR, 'THINR', one_row)\n",
    "            one_row = create_feature_names(TLINR, 'TLINR', one_row)\n",
    "            one_row = create_feature_names(TELNR, 'TELNR', one_row)\n",
    "\n",
    "\n",
    "            # feature: Crescendo and Decrescendo + their statistics:\n",
    "\n",
    "\n",
    "            C = np.zeros((CD.shape))\n",
    "            C[np.where(CD=='c')] = 1\n",
    "            len_seq_C, number_seq_C = CD_seq_finder(ar=C) \n",
    "            number_seq_C_1D = np.sum(number_seq_C)\n",
    "            Cmean2, Cstd2, Cskew2, Ckurt2, Cmax2, Cmin2 = six_statistics(len_seq_C,True)\n",
    "\n",
    "            D = np.zeros((CD.shape))\n",
    "            D[np.where(CD=='d')] = 1\n",
    "            len_seq_D, number_seq_D = CD_seq_finder(ar=D)\n",
    "            number_seq_D_1D = np.sum(number_seq_D)\n",
    "            Dmean2, Dstd2, Dskew2, Dkurt2, Dmax2, Dmin2 = six_statistics(len_seq_D,True)\n",
    "\n",
    "            one_row = create_feature_names(number_seq_C_1D, 'number_cresendo_notes', one_row)\n",
    "            one_row = create_feature_names(Cmean2, 'Cmean', one_row)\n",
    "            one_row = create_feature_names(Cstd2, 'Cstd', one_row)\n",
    "            one_row = create_feature_names(Cskew2, 'Cskew', one_row)\n",
    "            one_row = create_feature_names(Ckurt2, 'Ckurt', one_row)\n",
    "            one_row = create_feature_names(Cmax2, 'Cmax', one_row)\n",
    "            one_row = create_feature_names(Cmin2, 'Cmin', one_row) \n",
    "\n",
    "            one_row = create_feature_names(number_seq_D_1D, 'number_decresendo_notes', one_row)\n",
    "\n",
    "            one_row = create_feature_names(Dmean2, 'Dmean', one_row)\n",
    "            one_row = create_feature_names(Dstd2, 'Dstd', one_row)\n",
    "            one_row = create_feature_names(Dskew2, 'Dskew', one_row)\n",
    "            one_row = create_feature_names(Dkurt2, 'Dkurt', one_row)\n",
    "            one_row = create_feature_names(Dmax2, 'Dmax', one_row)\n",
    "            one_row = create_feature_names(Dmin2, 'Dmin', one_row) \n",
    "\n",
    "\n",
    "            # feature: Note Duration statistics:\n",
    "\n",
    "            ndmean2, ndstd2, ndskew2, ndkurt2, ndmax2, ndmin2  = six_statistics(nd,True)\n",
    "            '''\n",
    "            one_row = create_feature_names(ndmean2, 'ndmean', one_row)\n",
    "            one_row = create_feature_names(ndstd2, 'ndstd', one_row)\n",
    "            one_row = create_feature_names(ndskew2, 'ndskew', one_row)\n",
    "            one_row = create_feature_names(ndkurt2, 'ndkurt', one_row)\n",
    "            one_row = create_feature_names(ndmax2, 'ndmax', one_row)\n",
    "            one_row = create_feature_names(ndmin2, 'ndmin', one_row) \n",
    "            '''\n",
    "\n",
    "            # feature: note duration distribution:\n",
    "\n",
    "            SNR, MLNR, LNR = note_intensity_distribution(nd, ndmean2, ndstd2,True)\n",
    "\n",
    "            one_row = create_feature_names(SNR, 'SNR', one_row)\n",
    "            one_row = create_feature_names(MLNR, 'MLNR', one_row)\n",
    "            one_row = create_feature_names(LNR, 'LNR', one_row)\n",
    "\n",
    "\n",
    "            # featue: ratios of note duration transitions:\n",
    "            a,b,c,d,e,f, TLNR,TSNR,TELNR = ratios_of_transition_NS_1D(nd, True)\n",
    "\n",
    "            one_row = create_feature_names(TLNR, 'TLNR', one_row)\n",
    "            one_row = create_feature_names(TSNR, 'TSNR', one_row)\n",
    "            one_row = create_feature_names(TELNR, 'TELNR', one_row)\n",
    "\n",
    "\n",
    "            # feature: Staccato Ratio, Legato Ratio, Other Transitions Ratio + their note durations\n",
    "            # their statistics:\n",
    "\n",
    "            art = articulation_detection(time_passed_ar,pause_collector,nd_short,True)\n",
    "\n",
    "            #art = articulation_detection(time_passed_ar,pause_collector,nd,True)\n",
    "            nd_flat = nd.flatten()\n",
    "            nd_flat = (nd_flat[np.where(nd_flat!=-1)])[:-1] # make it shorter because it will deal\n",
    "            # with the art array which looks at the relation of note pairs and is therefore one note \n",
    "            # shorter\n",
    "            nd_flat = nd_flat.reshape((1,len(nd_flat)))\n",
    "            art = art.reshape((1,len(art)))\n",
    "            \n",
    "            SR, LR, OTR, SNDR, LNDR, OTNDR, nd_S, nd_L, nd_OT = art_ratios(art, nd_flat)\n",
    "\n",
    "            nd_Smean2, nd_Sstd2, nd_Sskew2, nd_Skurt2, nd_Smax2, nd_Smin2 = six_statistics(nd_S,True)\n",
    "            nd_Lmean2, nd_Lstd2, nd_Lskew2, nd_Lkurt2, nd_Lmax2, nd_Lmin2 = six_statistics(nd_L,True)\n",
    "            nd_OTmean2, nd_OTstd2, nd_OTskew2, nd_OTkurt2, nd_OTmax2, nd_OTmin2 = six_statistics(nd_OT,True)\n",
    "\n",
    "            one_row = create_feature_names(SR, 'SR', one_row)\n",
    "            one_row = create_feature_names(LR, 'LR', one_row)\n",
    "            one_row = create_feature_names(OTR, 'OTR', one_row)\n",
    "            one_row = create_feature_names(SNDR, 'SNDR', one_row)\n",
    "            one_row = create_feature_names(LNDR, 'LNDR', one_row)\n",
    "            one_row = create_feature_names(OTNDR, 'OTNDR', one_row)               \n",
    "\n",
    "            one_row = create_feature_names(nd_Smean2, 'nd_Smean', one_row)\n",
    "            one_row = create_feature_names(nd_Sstd2, 'nd_Sstd', one_row)\n",
    "            one_row = create_feature_names(nd_Sskew2, 'nd_Sskew', one_row)\n",
    "            one_row = create_feature_names(nd_Skurt2, 'nd_Skurt', one_row)\n",
    "            one_row = create_feature_names(nd_Smax2, 'nd_Smax', one_row)\n",
    "            one_row = create_feature_names(nd_Smin2, 'nd_Smin', one_row)             \n",
    "\n",
    "            one_row = create_feature_names(nd_Lmean2, 'nd_Lmean', one_row)\n",
    "            one_row = create_feature_names(nd_Lstd2, 'nd_Lstd', one_row)\n",
    "            one_row = create_feature_names(nd_Lskew2, 'nd_Lskew', one_row)\n",
    "            one_row = create_feature_names(nd_Lkurt2, 'nd_Lkurt', one_row)\n",
    "            one_row = create_feature_names(nd_Lmax2, 'nd_Lmax', one_row)\n",
    "            one_row = create_feature_names(nd_Lmin2, 'nd_Lmin', one_row)             \n",
    "\n",
    "            one_row = create_feature_names(nd_OTmean2, 'nd_OTmean', one_row)\n",
    "            one_row = create_feature_names(nd_OTstd2, 'nd_OTstd', one_row)\n",
    "            one_row = create_feature_names(nd_OTskew2, 'nd_OTskew', one_row)\n",
    "            one_row = create_feature_names(nd_OTkurt2, 'nd_OTkurt', one_row)\n",
    "            one_row = create_feature_names(nd_OTmax2, 'nd_OTmax', one_row)\n",
    "            one_row = create_feature_names(nd_OTmin2, 'nd_OTmin', one_row)             \n",
    "\n",
    "            print(f'done: getting features out of midi with instructions of Panda et al for {file_name}\\n')\n",
    "\n",
    "            ########################################################################\n",
    "            # Ending with one sample by extending all rows by its dictionary row:\n",
    "            rows.append(one_row) # all rows together appended by one sample\n",
    "            first_file_loop = False\n",
    "         #   except: \n",
    "          #      with open(f'{aimed_directory}/failed_xml2csv_file_names','a') as f:\n",
    "           #         f.write(file_name+'\\n')\n",
    "                    # here should be especially files which are not human generated\n",
    "\n",
    "    cols = list(one_row.keys())\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=cols)#.set_index(\"name\")\n",
    "    df = df.replace(float('nan'),-1)\n",
    "\n",
    "    # Writing dataframe to csv\n",
    "    df.to_csv(aim_storage_path_file) #f'{aimed_directory}/features_Panda_jSymbolic.csv') \n",
    "    print('done: whole process')\n",
    "    #except: # xml contains error such that convertion not possible\n",
    "    #with open(f'{aimed_directory}/failed_xml2csv_file_names','a') as f:\n",
    "     #   f.write(file_name+'\\n')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    " 1. Replace corrupted Internet midi files (human generator)<br>\n",
    "    Some files are really corrupted, others are simply not opening with the jSymbolic xml-file generator.<br>\n",
    " 2. Rename Internet midi files (human generator) to Folder_name + 'accompaniment.mid' to get the same file names as for the audio2midi generator midi files<br>\n",
    " 3. Open the jSymbolic program and generate a xml-file which will give us the variable value 'xml_path_file'.<br>\n",
    " 4. Extracting features out of midi files 'midi_path' and creating csv-files.<br>\n",
    " 5. After generating two .csv-files (one human generated, one audio2midi generated) keep the duplicate file_names ('sample_id') (so we get dataset B and B2) and drop the ONLY audio2midi generated samples (dataset A)\n",
    "</b>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Renaming the files done by humans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport glob\\nimport os\\npath_folder_names = '../midi-files-filtered2_Mvtausgetauscht_fehlerhafteFilesErsetzt_mitFoldern_14152022/*'\\nfor single_folder_path in glob.glob(path_folder_names):\\n    try:\\n        folder_name = single_folder_path.split('/')[-1]\\n        file_path = glob.glob(single_folder_path + '/*.mid')[0]\\n        new_name_path = single_folder_path  + '_accompaniment.mid'\\n        os.rename(file_path,new_name_path)\\n        os.rmdir(single_folder_path)\\n    except: \\n        pass\\nprint('done')\\n\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import glob\n",
    "import os\n",
    "path_folder_names = '../midi-files-filtered2_Mvtausgetauscht_fehlerhafteFilesErsetzt_mitFoldern_14152022/*'\n",
    "for single_folder_path in glob.glob(path_folder_names):\n",
    "    try:\n",
    "        folder_name = single_folder_path.split('/')[-1]\n",
    "        file_path = glob.glob(single_folder_path + '/*.mid')[0]\n",
    "        new_name_path = single_folder_path  + '_accompaniment.mid'\n",
    "        os.rename(file_path,new_name_path)\n",
    "        os.rmdir(single_folder_path)\n",
    "    except: \n",
    "        pass\n",
    "print('done')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. <br>\n",
    "Observation: the audio2midi generated midi files have only few content because jSymbolic needs only seconds to convert all of them (even with the files which are not existing as human generator midi files) into xml-files. However, for the human generated midi files the jSymbolic program runs out of storage. Nevertheless, that could happened because of bugs in the human generated midi files. A handful of midi files had to be replaced. Else the jSymbolic program could not extract features out of them. That was also the case for some other working midi files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  Extracting features out of midi files 'midi_path' and creating csv-files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "aim_folder = 'resulting_symbolic_dataframes' \n",
    "os.makedirs(aim_folder, exist_ok = True)\n",
    "title_start = 'symbolic_dataframe'\n",
    "\n",
    "midi_path_start = '../../stage1_data_collecting_phase/'\n",
    "\n",
    "storage_folder_xml = 'GeneratedXml_jSymbolic'\n",
    "title_start_xml = 'jSymbolic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> audio2midi converter Wang:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_wang = feature_extraction(aim_storage_path_file=f'{aim_folder}/{title_start}_audio2midiWang.csv',xml_path_file=f'{storage_folder_xml}/{title_start_xml}_audio2midiWang.xml',midi_path=midi_path_start+'audio2midi_converter/audio2midi_Wang/GeneratedMIDI_Wang', source_id='audio2midi generator')\n",
    "#df_wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> audio2midi generator with merged single voices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged = feature_extraction(aim_storage_path_file=f'{aim_folder}/{title_start}_audio2midiWang_mergedMIDIs.csv',xml_path_file=f'{storage_folder_xml}/{title_start_xml}_audio2midiWang_mergedMIDIs.xml',midi_path=midi_path_start+'audio2midi_converter/audio2midi_Wang/GeneratedFusionedMIDI_afterInstrumentalSplit', source_id='audio2midi generator merged')\n",
    "#df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> human generator full songs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_human = feature_extraction(aim_storage_path_file=f'{aim_folder}/{title_start}_human_fullSongs.csv',xml_path_file=f'{storage_folder_xml}/{title_start_xml}_human_fullSongs.xml',midi_path= midi_path_start+'webscraping/CollectedMIDI_webscraping_SolvedErrorsOfMvtAndCorruptedMIDI_RemovedFolderStructure', source_id='human generator')\n",
    "#df_human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> human generator with cut out snippets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_snippet = feature_extraction(aim_storage_path_file=f'{aim_folder}/{title_start}_human_snippets.csv',xml_path_file=f'{storage_folder_xml}/{title_start_xml}_human_snippets.xml',midi_path=midi_path_start+'webscraping/MIDISnippetGeneration/GeneratedMIDISnippets_webscraping', source_id='human generator snippet')\n",
    "#df_snippet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> audio2midi converter basic-pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current file: P_Rihanna_Umbrell_accompaniment\n",
      "done: convertion jSymbolic xml feature file into csv for P_Rihanna_Umbrell_accompaniment\n",
      "information extraction (and midi snippet generation) done\n",
      "done: getting features out of midi with instructions of Panda et al for P_Rihanna_Umbrell_accompaniment\n",
      "\n",
      "current file: K_Tschaikowski_Schwane_accompaniment\n",
      "done: convertion jSymbolic xml feature file into csv for K_Tschaikowski_Schwane_accompaniment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  if __name__ == \"__main__\":\n",
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if __name__ == \"__main__\":\n",
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in subtract\n",
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in subtract\n",
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../stage1_data_collecting_phase/audio2midi_converter/audio2midi_BasicPitch/GeneratedMIDI_BasicPitch/K_Tschaikowski_Schwane_accompaniment.mid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8057/1858563824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_basic_pitch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maim_storage_path_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{aim_folder}/{title_start}_audio2midiBasicPitch.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxml_path_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{storage_folder_xml}/{title_start_xml}_human_audio2midiBasicPitch.xml'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmidi_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmidi_path_start\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'audio2midi_converter/audio2midi_BasicPitch/GeneratedMIDI_BasicPitch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'basic-pitch generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_basic_pitch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8057/4279038477.py\u001b[0m in \u001b[0;36mfeature_extraction\u001b[0;34m(aim_storage_path_file, xml_path_file, midi_path, source_id)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# basic tools for feature extraction:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mpause_collector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote_collector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote_collector_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_passed_ar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnd_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tools_panda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_collector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# mask to get only relevant channels/voices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Schreibtisch/ba_08102022/stage2_feature_extraction/symbolicFeatureExtraction/basic_info_extraction.py\u001b[0m in \u001b[0;36mbasic_tools_panda\u001b[0;34m(directory_path_with_tracks, file_name, start_time, end_time)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Loading the midi:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMidiFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{directory_path_with_tracks}/{file_name}.mid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mido/midifiles/midifiles.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, file, type, ticks_per_beat, charset, debug, clip, tracks)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../stage1_data_collecting_phase/audio2midi_converter/audio2midi_BasicPitch/GeneratedMIDI_BasicPitch/K_Tschaikowski_Schwane_accompaniment.mid'"
     ]
    }
   ],
   "source": [
    "#df_basic_pitch = feature_extraction(aim_storage_path_file=f'{aim_folder}/{title_start}_audio2midiBasicPitch.csv',xml_path_file=f'{storage_folder_xml}/{title_start_xml}_human_audio2midiBasicPitch.xml',midi_path=midi_path_start+'audio2midi_converter/audio2midi_BasicPitch/GeneratedMIDI_BasicPitch', source_id='basic-pitch generator')\n",
    "#df_basic_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
