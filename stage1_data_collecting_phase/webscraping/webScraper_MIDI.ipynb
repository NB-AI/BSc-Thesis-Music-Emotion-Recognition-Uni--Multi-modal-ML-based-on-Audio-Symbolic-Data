{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Collect data from the internet with automatic downloading. <br>\n",
    "* Activate the free windscribe VPN. For this purpose download the VPN on your system (per ubuntu command shell: https://www.geeksforgeeks.org/how-to-setup-vpn-on-ubuntu-linux-system-for-ip-spoofing-using-windscribe/, thorugh official webpage: https://windscribe.net/download ). Through the VPN we can change the IP, when the daily download limit of one webpage is already reached. However, the free version of windscribe has of course also its montly usage limit. To solve this, you can create several windscribe accounts.<br>\n",
    "Without delivering an e-mail address in account creation two GB are freely available per month. <br>\n",
    "You can make use of the following account: <br>\n",
    "User name: stage1_BA_MIDI <br>\n",
    "Password: findMIDI\n",
    "* As web driver and url opening browser Firefox is used. Therefore, you need Firefox as a webbrowser. Sometimes (around 50 downloads later) the driver dies. Reboot the computer to make it work again. When running the notebook answer 'Please, type starting index in it:' with the index of the sample to start.<br>\n",
    "* The webpage 'lvbeethoven.fr' is opened by url automatically instead of downloading because its structure is mixed up. Therefore, its the job of the user to download the belonging midi file. <br>\n",
    "* Finally, download manually missing classic titles from kunstderfuge.com. All missing classic titles should be listed in the file 'final_missing_titles'. Delete manually found titles from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import os # also needed to start the VPN \n",
    "\n",
    "import re\n",
    "\n",
    "# open webpages:\n",
    "import subprocess as sp\n",
    "import webbrowser\n",
    "\n",
    "# work with content on webpages:\n",
    "# approach 1:\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "# approach 2: \n",
    "# Has a function to click on objects like we would do with the mouse (.click())\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait # wait until a webpage counter goes to 0 or has loaded\n",
    "from selenium.webdriver.common.action_chains import ActionChains # go to a certain element of a webpage\n",
    "\n",
    "\n",
    "# for virus detection:\n",
    "from virustotal_python import Virustotal, VirustotalError \n",
    "\n",
    "import pprint # from pprint import pprint\n",
    "\n",
    "# for renaming file on which most lately worked\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "\n",
    "import magic # to see the real file type without its extension, like '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your version identical with original version \n",
      "-> numpy \n",
      "-> 1.21.6\n",
      "\n",
      "\n",
      "Your version identical with original version \n",
      "-> pandas \n",
      "-> 1.3.5\n",
      "\n",
      "\n",
      "For \n",
      "random \n",
      "python version needs to fit \n",
      "-> original version 3.7.3 \n",
      "-> your version 3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n",
      "\n",
      "\n",
      "For \n",
      "os \n",
      "python version needs to fit \n",
      "-> original version 3.7.3 \n",
      "-> your version 3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n",
      "\n",
      "\n",
      "Your version identical with original version \n",
      "-> re \n",
      "-> 2.2.1\n",
      "\n",
      "\n",
      "For \n",
      "subprocess \n",
      "python version needs to fit \n",
      "-> original version 3.7.3 \n",
      "-> your version 3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n",
      "\n",
      "\n",
      "For \n",
      "webbrowser \n",
      "python version needs to fit \n",
      "-> original version 3.7.3 \n",
      "-> your version 3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n",
      "\n",
      "\n",
      "Your version identical with original version \n",
      "-> requests \n",
      "-> 2.28.1\n",
      "\n",
      "\n",
      "Your version identical with original version \n",
      "-> bs4 \n",
      "-> 4.9.1\n",
      "\n",
      "\n",
      "Your version identical with original version \n",
      "-> selenium \n",
      "-> 4.1.3\n",
      "\n",
      "\n",
      "Possibly different versions: \n",
      "-> virustotal_python \n",
      "-> original version 0.2.0 \n",
      "-> your version  is not clearly visible. Go to your used python folder path .../python3.7/site-packages to investigate the version of your package. Also possible: have a look at the shell commands \"pip show module_name\" and \"apt show module_name\"\n",
      "\n",
      "\n",
      "Possibly different versions: \n",
      "-> pprint \n",
      "-> original version 0.40.0 \n",
      "-> your version  is not clearly visible. Go to your used python folder path .../python3.7/site-packages to investigate the version of your package. Also possible: have a look at the shell commands \"pip show module_name\" and \"apt show module_name\"\n",
      "\n",
      "\n",
      "Possibly different versions: \n",
      "-> shutil \n",
      "-> original version 1.0.0 \n",
      "-> your version  is not clearly visible. Go to your used python folder path .../python3.7/site-packages to investigate the version of your package. Also possible: have a look at the shell commands \"pip show module_name\" and \"apt show module_name\"\n",
      "\n",
      "\n",
      "Possibly different versions: \n",
      "-> time \n",
      "-> original version 3.1.2 \n",
      "-> your version  is not clearly visible. Go to your used python folder path .../python3.7/site-packages to investigate the version of your package. Also possible: have a look at the shell commands \"pip show module_name\" and \"apt show module_name\"\n",
      "\n",
      "\n",
      "Possibly different versions: \n",
      "-> magic \n",
      "-> original version 0.4.27 \n",
      "-> your version <function version at 0x7f474ad3a048>\n",
      "\n",
      "\n",
      "Your version identical with original version \n",
      "-> sys \n",
      "-> 3.7.3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../stage-1/overall_used_tools')\n",
    "import requirements_check as rc\n",
    "\n",
    "import bs4, selenium, virustotal_python\n",
    "rc.check(sys, [np,pd,random,os,re,sp,webbrowser,requests,bs4,selenium,virustotal_python,pprint,shutil,time,magic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting information out of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>MP3-Code</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H001</td>\n",
       "      <td>H_Trailerpark_Schlech</td>\n",
       "      <td>Trailerpark</td>\n",
       "      <td>Schlechter Tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H002</td>\n",
       "      <td>H_Desiigner_Panda</td>\n",
       "      <td>Desiigner</td>\n",
       "      <td>Panda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H003</td>\n",
       "      <td>H_NAS_DooRags</td>\n",
       "      <td>NAS</td>\n",
       "      <td>Doo Rags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H004</td>\n",
       "      <td>H_DMX_XGonGiv</td>\n",
       "      <td>DMX</td>\n",
       "      <td>X Gon' Give It To Ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H005</td>\n",
       "      <td>H_Xatar_MeineGr</td>\n",
       "      <td>Xatar</td>\n",
       "      <td>Meine Gro√üe Liebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>P142</td>\n",
       "      <td>P_Oasis_DontLoo</td>\n",
       "      <td>Oasis</td>\n",
       "      <td>Don't Look Back In Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>P143</td>\n",
       "      <td>P_DerJungemitderGitarre_HalloWo</td>\n",
       "      <td>Der Junge mit der Gitarre</td>\n",
       "      <td>Hallo Worum Gehts Ich Bin Dagegen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>P144</td>\n",
       "      <td>P_ChrisBrown_Forever</td>\n",
       "      <td>Chris Brown</td>\n",
       "      <td>Forever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>P145</td>\n",
       "      <td>P_RyanAdams_LuckyNo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ryan Adams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>P146</td>\n",
       "      <td>P_AmyWinehouse_BackToB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amy Winehouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Code                         MP3-Code                     Artist  \\\n",
       "0    H001            H_Trailerpark_Schlech                Trailerpark   \n",
       "1    H002                H_Desiigner_Panda                  Desiigner   \n",
       "2    H003                    H_NAS_DooRags                        NAS   \n",
       "3    H004                    H_DMX_XGonGiv                        DMX   \n",
       "4    H005                  H_Xatar_MeineGr                      Xatar   \n",
       "..    ...                              ...                        ...   \n",
       "365  P142                  P_Oasis_DontLoo                      Oasis   \n",
       "366  P143  P_DerJungemitderGitarre_HalloWo  Der Junge mit der Gitarre   \n",
       "367  P144             P_ChrisBrown_Forever                Chris Brown   \n",
       "368  P145              P_RyanAdams_LuckyNo                        NaN   \n",
       "369  P146           P_AmyWinehouse_BackToB                        NaN   \n",
       "\n",
       "                                 Title  \n",
       "0                       Schlechter Tag  \n",
       "1                                Panda  \n",
       "2                             Doo Rags  \n",
       "3                 X Gon' Give It To Ya  \n",
       "4                    Meine Gro√üe Liebe  \n",
       "..                                 ...  \n",
       "365           Don't Look Back In Anger  \n",
       "366  Hallo Worum Gehts Ich Bin Dagegen  \n",
       "367                            Forever  \n",
       "368                         Ryan Adams  \n",
       "369                      Amy Winehouse  \n",
       "\n",
       "[370 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../../stage0_provided_information/gems-emotion-tags-main/data/GEMS_songs_overview.csv'\n",
    "small = pd.read_csv(path, skiprows=1)\n",
    "small2 = small[['Code','MP3-Code','Artist','Title']]\n",
    "small3 = small2.dropna(how='all') # remove all rows only containing nan\n",
    "small3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code                       P145\n",
      "MP3-Code    P_RyanAdams_LuckyNo\n",
      "Artist                      NaN\n",
      "Title                Ryan Adams\n",
      "Name: 368, dtype: object\n",
      "Code                          P146\n",
      "MP3-Code    P_AmyWinehouse_BackToB\n",
      "Artist                         NaN\n",
      "Title                Amy Winehouse\n",
      "Name: 369, dtype: object\n",
      "number of nan-s for title and/or artist: 2\n",
      "number nan-s for mp3 code:  3\n"
     ]
    }
   ],
   "source": [
    "number_term_nan=0\n",
    "number_mp3_nan=0\n",
    "col = small3.columns\n",
    "for i ,row in small3.iterrows():\n",
    "    curr_code = row[col[0]]\n",
    "    curr_mp3 =  row[col[1]]\n",
    "    curr_art =  row[col[2]]\n",
    "    curr_song =  row[col[3]]\n",
    "    \n",
    "    \n",
    "    if pd.isna(curr_art) or pd.isna(curr_song):\n",
    "        number_term_nan +=1\n",
    "        print(row)\n",
    "    \n",
    "    if pd.isna(curr_mp3): # replace missing MP3-ID with code \n",
    "        small3.at[i, 'MP3-Code'] = small3.at[i, 'Code']\n",
    "        number_mp3_nan+=1\n",
    "\n",
    "\n",
    "print('number of nan-s for title and/or artist:', number_term_nan)\n",
    "print('number nan-s for mp3 code: ', number_mp3_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mixed up lines from above are corrected:\n",
    "small3.at[368, 'Artist'] = 'Ryan Adams'\n",
    "small3.at[368, 'Title'] = 'Lucky Now'\n",
    "\n",
    "small3.at[369, 'Artist'] = 'Amy Winehouse'\n",
    "small3.at[369, 'Title'] = 'Back to Back'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct falsly written titles and artists:\n",
    "small3.at[254, 'Artist'] = 'Katy Perry' # was orignally written 'Katie Perry' what is wrong; correct it here\n",
    "small3.at[238, 'Title'] = 'Poker Face' # original: 'Pokerface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders in which data shall be stored\n",
    "codes = small3['MP3-Code']\n",
    "\n",
    "path = 'midi-files'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "for i in codes:\n",
    "    path2 = os.path.join(path, str(i))\n",
    "    try:\n",
    "        os.mkdir(path2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try: \n",
    "        path3 = os.path.join(path2, 'demo')\n",
    "        path3a = os.path.join(path3, 'webpageinfo.txt')\n",
    "        \n",
    "        path4 = os.path.join(path2, 'full')\n",
    "        path4a = os.path.join(path4, 'webpageinfo.txt')\n",
    "        \n",
    "        \n",
    "        os.mkdir(path3)\n",
    "        open(path3a,'w') # create file in which the related web pages shall be stored\n",
    "        \n",
    "        os.mkdir(path4)\n",
    "        open(path4a,'w')\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/c/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>MP3-Code</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>search_for</th>\n",
       "      <th>search_for2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H001</td>\n",
       "      <td>H_Trailerpark_Schlech</td>\n",
       "      <td>Trailerpark</td>\n",
       "      <td>Schlechter Tag</td>\n",
       "      <td>Trailerpark Schlechter Tag</td>\n",
       "      <td>Trailerpark - Schlechter Tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H002</td>\n",
       "      <td>H_Desiigner_Panda</td>\n",
       "      <td>Desiigner</td>\n",
       "      <td>Panda</td>\n",
       "      <td>Desiigner Panda</td>\n",
       "      <td>Desiigner - Panda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H003</td>\n",
       "      <td>H_NAS_DooRags</td>\n",
       "      <td>NAS</td>\n",
       "      <td>Doo Rags</td>\n",
       "      <td>NAS Doo Rags</td>\n",
       "      <td>NAS - Doo Rags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H004</td>\n",
       "      <td>H_DMX_XGonGiv</td>\n",
       "      <td>DMX</td>\n",
       "      <td>X Gon' Give It To Ya</td>\n",
       "      <td>DMX X Gon' Give It To Ya</td>\n",
       "      <td>DMX - X Gon' Give It To Ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H005</td>\n",
       "      <td>H_Xatar_MeineGr</td>\n",
       "      <td>Xatar</td>\n",
       "      <td>Meine Gro√üe Liebe</td>\n",
       "      <td>Xatar Meine Gro√üe Liebe</td>\n",
       "      <td>Xatar - Meine Gro√üe Liebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>P142</td>\n",
       "      <td>P_Oasis_DontLoo</td>\n",
       "      <td>Oasis</td>\n",
       "      <td>Don't Look Back In Anger</td>\n",
       "      <td>Oasis Don't Look Back In Anger</td>\n",
       "      <td>Oasis - Don't Look Back In Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>P143</td>\n",
       "      <td>P_DerJungemitderGitarre_HalloWo</td>\n",
       "      <td>Der Junge mit der Gitarre</td>\n",
       "      <td>Hallo Worum Gehts Ich Bin Dagegen</td>\n",
       "      <td>Der Junge mit der Gitarre Hallo Worum Gehts Ic...</td>\n",
       "      <td>Der Junge mit der Gitarre - Hallo Worum Gehts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>P144</td>\n",
       "      <td>P_ChrisBrown_Forever</td>\n",
       "      <td>Chris Brown</td>\n",
       "      <td>Forever</td>\n",
       "      <td>Chris Brown Forever</td>\n",
       "      <td>Chris Brown - Forever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>P145</td>\n",
       "      <td>P_RyanAdams_LuckyNo</td>\n",
       "      <td>Ryan Adams</td>\n",
       "      <td>Lucky Now</td>\n",
       "      <td>Ryan Adams Lucky Now</td>\n",
       "      <td>Ryan Adams - Lucky Now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>P146</td>\n",
       "      <td>P_AmyWinehouse_BackToB</td>\n",
       "      <td>Amy Winehouse</td>\n",
       "      <td>Back to Back</td>\n",
       "      <td>Amy Winehouse Back to Back</td>\n",
       "      <td>Amy Winehouse - Back to Back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Code                         MP3-Code                     Artist  \\\n",
       "0    H001            H_Trailerpark_Schlech                Trailerpark   \n",
       "1    H002                H_Desiigner_Panda                  Desiigner   \n",
       "2    H003                    H_NAS_DooRags                        NAS   \n",
       "3    H004                    H_DMX_XGonGiv                        DMX   \n",
       "4    H005                  H_Xatar_MeineGr                      Xatar   \n",
       "..    ...                              ...                        ...   \n",
       "365  P142                  P_Oasis_DontLoo                      Oasis   \n",
       "366  P143  P_DerJungemitderGitarre_HalloWo  Der Junge mit der Gitarre   \n",
       "367  P144             P_ChrisBrown_Forever                Chris Brown   \n",
       "368  P145              P_RyanAdams_LuckyNo                 Ryan Adams   \n",
       "369  P146           P_AmyWinehouse_BackToB              Amy Winehouse   \n",
       "\n",
       "                                 Title  \\\n",
       "0                       Schlechter Tag   \n",
       "1                                Panda   \n",
       "2                             Doo Rags   \n",
       "3                 X Gon' Give It To Ya   \n",
       "4                    Meine Gro√üe Liebe   \n",
       "..                                 ...   \n",
       "365           Don't Look Back In Anger   \n",
       "366  Hallo Worum Gehts Ich Bin Dagegen   \n",
       "367                            Forever   \n",
       "368                          Lucky Now   \n",
       "369                       Back to Back   \n",
       "\n",
       "                                            search_for  \\\n",
       "0                           Trailerpark Schlechter Tag   \n",
       "1                                      Desiigner Panda   \n",
       "2                                         NAS Doo Rags   \n",
       "3                             DMX X Gon' Give It To Ya   \n",
       "4                              Xatar Meine Gro√üe Liebe   \n",
       "..                                                 ...   \n",
       "365                     Oasis Don't Look Back In Anger   \n",
       "366  Der Junge mit der Gitarre Hallo Worum Gehts Ic...   \n",
       "367                                Chris Brown Forever   \n",
       "368                               Ryan Adams Lucky Now   \n",
       "369                         Amy Winehouse Back to Back   \n",
       "\n",
       "                                           search_for2  \n",
       "0                         Trailerpark - Schlechter Tag  \n",
       "1                                    Desiigner - Panda  \n",
       "2                                       NAS - Doo Rags  \n",
       "3                           DMX - X Gon' Give It To Ya  \n",
       "4                            Xatar - Meine Gro√üe Liebe  \n",
       "..                                                 ...  \n",
       "365                   Oasis - Don't Look Back In Anger  \n",
       "366  Der Junge mit der Gitarre - Hallo Worum Gehts ...  \n",
       "367                              Chris Brown - Forever  \n",
       "368                             Ryan Adams - Lucky Now  \n",
       "369                       Amy Winehouse - Back to Back  \n",
       "\n",
       "[370 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add columns to our dataframe, these will be used to search for the certain samples in the web:\n",
    "small3['search_for'] = small3['Artist'] + ' '+ small3['Title']\n",
    "small3['search_for2'] = small3['Artist'] + ' - '+ small3['Title']\n",
    "small3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer():\n",
    "    '''When webpage response != 200, activate this function'''\n",
    "    \n",
    "    #answer = input('Webpage could not be opened. Shall be continued?[y/n]')\n",
    "    #while answer != 'y':\n",
    "    #    answer = input('Webpage could not be opened. Shall be continued?[y/n]')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_(url):\n",
    "    '''function to open url for manual download'''\n",
    "    \n",
    "    print('Please, have a look at the opening webpage (Firefox used) and download the wished midi file(s)...')\n",
    "    print('WARNING: The current webpage will be opened on Firefox. THIS jupyter notebook shall be run on an other browser because Firefox will be closed automatically!')\n",
    "    print('In this case you have to type in \\n{search_term2}\\n in the search bar of the webpage to find the file.')\n",
    "    #webbrowser.open(url) # open webpage for the use\n",
    "\n",
    "    child = sp.Popen(\"firefox %s\" % url, shell=True)\n",
    "\n",
    "    answer = input('Are you done with looking?[y/n]')\n",
    "    while answer != 'y':\n",
    "        answer = input('Are you done with looking?[y/n]')\n",
    "    os.system(\"pkill \"+\"firefox\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(download_url:str, download_path_mp3code:str, download_page:str):\n",
    "    '''download a file by only using the url.'''\n",
    "    \n",
    "    # check which name the file to download will get. We count the number of files in the folder such that\n",
    "    # they won't get the same name: e. g., file1, file2, file3 as resulting files\n",
    "    dir_name = os.path.dirname(download_path_mp3code)\n",
    "    number_files = len(os.listdir(dir_name))\n",
    "    \n",
    "   # download_url = 'http://www.rppmf.com/coldplay/2000-parachutes/05-coldplay_2000-yellow-[k].mid'\n",
    "    \n",
    "    # download from certain webpage:\n",
    "    r = requests.get(download_url)\n",
    "    \n",
    "    download_path_mp3code_splitted = download_path_mp3code.split('.')\n",
    "    mid_path_name = download_path_mp3code_splitted[0] + '_' + str(number_files) + '.mid'# + download_path_mp3code_splitted[1] \n",
    "    with open(mid_path_name,'wb') as f: \n",
    "        f.write(r.content)\n",
    "    \n",
    "    \n",
    "    # write in txt file in folder from which webpage we downloaded midi file:\n",
    "   # textfile_path = dir_name + '/webpageinfo.txt'\n",
    "    #with open(textfile_path, 'a') as t:\n",
    "     #   t.write(download_page)\n",
    "      #  t.write('\\n')\n",
    "        \n",
    "    full_path_split = os.path.realpath(dir_name).split('.')\n",
    "    full_path_name = full_path_split[0] + '_' + str(number_files) + '.' + download_path_mp3code_splitted[1]\n",
    "    return mid_path_name #, full_path_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_downloaded_file(download_path_mp3code:str, download_page:str):\n",
    "    '''change name of the file downloaded most lately'''\n",
    "    \n",
    "    # check which name the file to download will get. We count the number of files in the folder such that\n",
    "    # they won't get the same name: e. g., file1, file2, file3 as resulting files\n",
    "    \n",
    "    dir_name = os.path.dirname(download_path_mp3code)\n",
    "    number_files = len(os.listdir(dir_name))\n",
    "    \n",
    "    \n",
    "    # create wished file name:\n",
    "    file_name = os.path.basename(download_path_mp3code)\n",
    "    file_name_split = file_name.split('.')\n",
    "    storage_name = file_name_split[0] + '_' + str(number_files) + '.mid'# + file_name_split[1]\n",
    "    \n",
    "    # find storage path:\n",
    "    full_path = os.path.abspath(download_path_mp3code)\n",
    "    full_path = full_path.replace(file_name, '')\n",
    "    print(full_path)\n",
    "    # Give file last time touched the new name:\n",
    "    filename_ = max([full_path  + f for f in os.listdir(full_path)],key=os.path.getctime)\n",
    "    shutil.move(filename_,os.path.join(full_path,storage_name))\n",
    "    #time.sleep(10)\n",
    "\n",
    "    \n",
    "\n",
    "    # get absolute path to return:\n",
    "    download_path_mp3code_splitted = download_path_mp3code.split('.')\n",
    "    mid_path_name = download_path_mp3code_splitted[0] + '_' + str(number_files) + '.' + download_path_mp3code_splitted[1] \n",
    "    \n",
    "    return mid_path_name#os.path.join(full_path,storage_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def webpage_virus_check(url:str):\n",
    "    ''' URL virus check '''\n",
    "    \n",
    "    global day_limit_counter\n",
    "    day_limit_counter += 1\n",
    "    return 1\n",
    "    # Retrieved from: \n",
    "    # https://pypi.org/project/virustotal-python/\n",
    "    vtotal = Virustotal(API_KEY='7d3d966b2b57f558b1d6097b8ee5a5e18dd92c68a1eedd03e02caef10db22ed2')\n",
    "    #vtotal = Virustotal(API_KEY='60b7611fa8b76bc01429c6ef111656f1088c65fe565a5e011fa91c94feb0acba')\n",
    "    # these are virus total ID keys. We have a daily checking limit of 500 files/urls. When the first\n",
    "    # key does not work anymore, use the second one. When both reached their limits create a new key on \n",
    "    # https://pypi.org/project/virustotal-python/ or wait a day. \n",
    "    \n",
    "    done = False\n",
    "    while done == False:\n",
    "        try:\n",
    "            resp = vtotal.request(\"url/scan\", params={\"url\": url}, method=\"POST\")\n",
    "     \n",
    "            # Send a URL to VirusTotal for analysis\n",
    "            url_resp = resp.json()\n",
    "            # Obtain scan_id\n",
    "            scan_id = url_resp[\"scan_id\"]\n",
    "            # Request report for URL analysis\n",
    "            analysis_resp = vtotal.request(\"url/report\", params={\"resource\": scan_id})\n",
    "\n",
    "            malware_suspciton = len(re.findall('malware site', str(analysis_resp.json())))\n",
    "            malicious_suspciton = len(re.findall('malicious site', str(analysis_resp.json())))\n",
    "            \n",
    "  \n",
    "            if (malware_suspciton + malicious_suspciton) > 2:\n",
    "\n",
    "                \n",
    "                return -1\n",
    "        \n",
    "            elif (malware_suspciton + malicious_suspciton) > 0 or ('Resource does not exist in the dataset' == analysis_resp.json()['verbose_msg']):\n",
    "\n",
    "                return 0\n",
    "            \n",
    "            else: # clean url\n",
    "                return 1\n",
    "                \n",
    "            done = True\n",
    "\n",
    "        except: # because it is no premium API key, we can only make 4 virus checks per minute.\n",
    "            print('wait url check....')\n",
    "            time.sleep(60)\n",
    "\n",
    "    '''\n",
    "    free API key limits:\n",
    "\n",
    "    Request rate\t4 lookups / min\n",
    "    # thats problematically slow\n",
    "    # set time.sleep(60) after 4 lookups\n",
    "    # you could look at each webpage once for the virus scan with assumption either all files with virus or all\n",
    "    # files clean.\n",
    "\n",
    "\n",
    "    Daily quota\t500 lookups / day\n",
    "    Monthly quota\t15.50 K lookups / month\n",
    "    ''';\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_virus_check(FILE_PATH:str):\n",
    "        ''' file virus check, FILE_PATH e. g. 'yo/err.MID'  '''\n",
    "        \n",
    "        global day_limit_counter\n",
    "        day_limit_counter += 1\n",
    "        \n",
    "        return 1\n",
    "\n",
    "        done = False\n",
    "        vtotal = Virustotal(API_KEY='7d3d966b2b57f558b1d6097b8ee5a5e18dd92c68a1eedd03e02caef10db22ed2')\n",
    "        #vtotal = Virustotal(API_KEY='60b7611fa8b76bc01429c6ef111656f1088c65fe565a5e011fa91c94feb0acba')\n",
    "        while done == False:\n",
    "            try:\n",
    "                # Create report:\n",
    "\n",
    "                # Create dictionary containing the file to send for multipart encoding upload\n",
    "                files = {\"file\": (os.path.basename(FILE_PATH), open(os.path.abspath(FILE_PATH), \"rb\"))}\n",
    "                \n",
    "                # v2 example\n",
    "                resp = vtotal.request(\"file/scan\", files=files, method=\"POST\")\n",
    "\n",
    "                # The v2 API returns a response_code\n",
    "                # This property retrieves it from the JSON response\n",
    "\n",
    "                # Print JSON response from the API:\n",
    "\n",
    "                # Call report content:\n",
    "                FILE_ID = str(resp.json()['scan_id']) # get the ID for of the file scan process\n",
    "\n",
    "                resp = vtotal.request(\"file/report\", {\"resource\": FILE_ID})\n",
    "              \n",
    "                if \"\\'detected\\': True\" in str(resp.data):\n",
    "                    os.remove(os.path.abspath(FILE_PATH))\n",
    "                    print('file dangerous removed')\n",
    "                    return -1\n",
    "\n",
    "                else: # file seems to be okay\n",
    "                    return 1\n",
    "                \n",
    "                done = True\n",
    "                \n",
    "            except:\n",
    "                print('wait file check....')\n",
    "                time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_shim(passed_in_driver, object):\n",
    "    ''' needed when we want to find an object by location. The reason for this is when we get an error \n",
    "    messeage that one element overlays the other one.'''\n",
    "    \n",
    "    x = object.location['x']\n",
    "    y = object.location['y']\n",
    "    scroll_by_coord = 'window.scrollTo(%s,%s);' % (\n",
    "        x,\n",
    "        y\n",
    "    )\n",
    "    scroll_nav_out_of_way = 'window.scrollBy(0, -120);'\n",
    "    passed_in_driver.execute_script(scroll_by_coord)\n",
    "    passed_in_driver.execute_script(scroll_nav_out_of_way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## webpage search functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a look at all webpages which were used for automatic download. One webpage = one function. E. g.  bitmidicom() downloads from bitmidi.com ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bitmidicom(search_term:str, song_name:str, download_path_mp3code:str):\n",
    "    ''' DOWNLOAD, also other versions downloaded'''\n",
    "    \n",
    "    global day_limit_counter\n",
    "    # the target we want to open  \n",
    "    search_term = search_term.replace(' ', '-').replace('&','and').replace(\"'\",\"\").replace('!','').replace('?','')\n",
    "    song_name = song_name.replace(' ', '-').replace('&','and').replace(\"'\",\"\").replace('!','').replace('?','')\n",
    "    url='https://bitmidi.com/' + search_term   + '-mid'\n",
    "    \n",
    "    # open with GET method:\n",
    "    resp=requests.get(url, headers={'User-Agent': 'anything'})\n",
    "\n",
    "    if resp.status_code==200: # webpage can be opened; artist with song exsting\n",
    "        \n",
    "        soup=BeautifulSoup(resp.text,'html.parser') \n",
    "        for a in soup.find_all('a'):\n",
    "\n",
    "            try:\n",
    "                if 'upload' in a['href']:\n",
    "                    \n",
    "                    download_url = 'https://bitmidi.com' + a['href']\n",
    "                    \n",
    "                    if day_limit_counter < 500:\n",
    "                        url_check = webpage_virus_check(download_url)\n",
    "                        \n",
    "                        if url_check > -1: # url could be suspicious but don't have to be\n",
    "                            path_file_updated = download(download_url, download_path_mp3code, 'bitmidicom')\n",
    "                            \n",
    "                            if 'text' in magic.from_file(download_path_mp3code): # can be HTML code or text file\n",
    "                                # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                                os.remove(download_path_mp3code) # delete the unneeded file\n",
    "                            \n",
    "                            elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                                file_virus_check(path_file_updated)\n",
    "                                \n",
    "                            elif url_check == 0 and day_limit_counter >= 500:\n",
    "                                with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                    f.write(f'{search_term} bitmidicom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                                return -1\n",
    "                        else:\n",
    "                            with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                                f.write(f'bitmidicom {search_term} {download_url}\\n')\n",
    "                                \n",
    "                    else:\n",
    "                        with open('where_we_stopped_collecting', 'a') as f:\n",
    "                            f.write(f'{search_term} bitmidicom\\n unfinished download \\n {download_url}')\n",
    "                        return -1 \n",
    "                                \n",
    "            except:\n",
    "                pass\n",
    "             \n",
    "\n",
    "        # finding all other song versions and also download them:\n",
    "        for s in soup.find_all('div', {'class':'mv4'}):\n",
    "            if 'Related MIDI Files' in str(s): \n",
    "                for ss in s.find_all('a', {'class':'pointer no-underline fw4 white underline-hover'}):\n",
    "                    # loop over all related midi files for the case we have a second version of\n",
    "                    # the same song there. Download all versions of one song.\n",
    "\n",
    "                    try:\n",
    "                        if song_name in ss['href']:\n",
    "                            url_next_version = 'https://bitmidi.com' + ss['href']\n",
    "                            resp_next=requests.get(url_next_version, headers={'User-Agent': 'anything'})\n",
    "                            soup_next=BeautifulSoup(resp_next.text,'html.parser') \n",
    "\n",
    "                            for a_next in soup_next.find_all('a'):\n",
    "\n",
    "                                try:\n",
    "                                    if 'upload' in a_next['href']:\n",
    "                                        download_url_next = 'https://bitmidi.com' + a_next['href']\n",
    "                                                                              \n",
    "                                        \n",
    "                                        if day_limit_counter < 500:\n",
    "                                            url_check = webpage_virus_check(download_url_next)\n",
    "\n",
    "                                            if url_check > -1: # url could be suspicious but don't have to be\n",
    "                                                path_file_updated = download(download_url_next, download_path_mp3code, 'bitmidicom')\n",
    "                                                \n",
    "                                                if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                                                    # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                                                    os.remove(path_file_updated) # delete the unneeded file\n",
    "\n",
    "                                                elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                                                    file_virus_check(path_file_updated)\n",
    "\n",
    "                                                elif url_check == 0 and day_limit_counter >= 500:\n",
    "                                                    with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                                        f.write(f'{search_term} bitmidicom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                                                    return -1\n",
    "                                            else:\n",
    "                                                with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                                                    f.write(f'bitmidicom {search_term} {download_url}\\n')\n",
    "                                        else:\n",
    "                                            with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                                f.write(f'{search_term} bitmidicom\\n unfinished download \\n {download_url}')\n",
    "                                            return -1\n",
    "                        \n",
    "                                        break\n",
    "                                except:\n",
    "                                    pass\n",
    "                    except:\n",
    "                        pass\n",
    "                break\n",
    "        \n",
    "        return 1\n",
    "\n",
    "    else:\n",
    "        # song does not exist on bitmidi.com\n",
    "        # answer()\n",
    "        return 0 \n",
    "    \n",
    "# Testing the download success with one example song for which we know that it already exists for this\n",
    "# webpage. Test download folder 'tester' has to be created:\n",
    "#os.makedirs('tester', exist_ok=True)\n",
    "#bitmidicom(search_term = 'lady gaga just dance', song_name='just dance', download_path_mp3code='tester/bitmidicom_idmp.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/c/Schreibtisch/ba_08102022/stage1_data_collecting_phase/webscraping/tester/\n"
     ]
    }
   ],
   "source": [
    "def freemidiorg(searched_artist:str, searched_song:str,download_path_mp3code:str):\n",
    "    '''DOWNLOAD WITH CLICK BECAUSE SOMETIMES ONLY THROUGH CLICKING DOWNLOAD POSSIBLE'''\n",
    "    \n",
    "    global day_limit_counter\n",
    "    \n",
    "    full_path = os.path.abspath(download_path_mp3code)\n",
    "    wished_file_name = full_path.split('/')[-1]\n",
    "    download_path = full_path.replace(wished_file_name, '')\n",
    "\n",
    "    # needed for selenium:\n",
    "    option = webdriver.FirefoxOptions()\n",
    "    option.headless = True # GUI does not open, but navigation through web suceeds\n",
    "    # determine where to save the downloaded files\n",
    "    #0 means to download to the desktop, 1 means to download to the default \"Downloads\" directory, 2 means to use the directory\n",
    "    option.set_preference(\"browser.download.folderList\", 2) \n",
    "    option.set_preference(\"browser.download.dir\", download_path)\n",
    "\n",
    "    searched_artist = searched_artist.replace('!','').replace('?','').lower()\n",
    "    searched_song = searched_song.lower().replace('&','and').replace(\"'\",\"\").replace('!','').replace('?','')\n",
    "\n",
    "    artist_start_letter = searched_artist[0]\n",
    "    artist_page_url = 'https://freemidi.org/artists-' + artist_start_letter\n",
    "    resp = requests.get(artist_page_url, headers={'User-Agent':'anything'})\n",
    "    if resp.status_code==200: # webpage can be opened\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        for a in soup.find_all('a'):\n",
    "\n",
    "            if searched_artist == a.get_text().lower():\n",
    "                url_songs_artist = 'https://freemidi.org/' + a['href']\n",
    "                resp2 = requests.get(url_songs_artist, headers={'User-Agent':'anything'})\n",
    "                soup2 = BeautifulSoup(resp2.text, 'html.parser')\n",
    "\n",
    "                for a2 in soup2.find_all('a'): # loop over all possible versions of one song\n",
    "                    if searched_song in a2.get_text().lower():\n",
    "                        url_song = 'https://freemidi.org/' + a2['href']\n",
    "                        driver = webdriver.Firefox(options=option)\n",
    "                        driver.get(url_song)\n",
    "\n",
    "                        ele = driver.find_element(by=By.LINK_TEXT, value='Download MIDI')\n",
    "\n",
    "                        if day_limit_counter < 500:\n",
    "                            url_check = webpage_virus_check(url_song)\n",
    "\n",
    "                            if url_check > -1: # url could be suspicious but don't have to be\n",
    "                                ele.click() # download by click\n",
    "                                time.sleep(1) # wait a second before renaming file. else we get an error \n",
    "                                path_file_updated = rename_downloaded_file(download_path_mp3code, 'freemidiorg')                               \n",
    "                               \n",
    "                                if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                                    # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                                    os.remove(path_file_updated) # delete the unneeded file\n",
    "                                \n",
    "                                elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                                    file_virus_check(path_file_updated)\n",
    "\n",
    "                                elif url_check == 0 and day_limit_counter >= 500:\n",
    "                                    with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                        f.write(f'{searched_artist} {searched_song} freemidiorg \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                                    return -1\n",
    "                            else:\n",
    "                                with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                                    f.write(f'freemidiorg {searched_artist} {searched_song}  {ele}\\n')\n",
    "                        else:\n",
    "                            with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                f.write(f'{searched_artist} {searched_song} freemidiorg\\n unfinished download \\n {ele}')\n",
    "                            return -1                        \n",
    "                        \n",
    "                break\n",
    "    else:\n",
    "        answer()\n",
    "\n",
    "#freemidiorg(searched_artist = 'lady gaga', searched_song = 'poker face', download_path_mp3code='tester/freemidiorg_P_LadyGaga_Pokerfa.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def midiworldcom(searched_artist:str, searched_song:str, download_path_mp3code:str):\n",
    "    ''' DOWNLOAD\n",
    "    type: following the architecture of the webpage by using url and searching the \n",
    "    result lists. In the urls are not the song titles and artist names but only numbers,\n",
    "    therefore, use soup.find_all() to get overview over page content and finding the\n",
    "    correct url links. '''\n",
    "    \n",
    "    global day_limit_counter\n",
    "    \n",
    "    # the target we want to open  \n",
    "    searched_artist = searched_artist.lower()\n",
    "    starting_letter = (searched_artist[0]).upper()\n",
    "    \n",
    "    searched_song = searched_song.lower().replace('&','and').replace(\"'\",\"\").replace('!','').replace('?','')\n",
    "    \n",
    "    for i in ['', range(100)]: # url changes with \n",
    "        \n",
    "        url1 = f\"https://www.midiworld.com/files/{starting_letter}/all/\" + str(i)#https://www.partnersinrhyme.com/midi/midiartists/index.shtml\"\n",
    "        soup = BeautifulSoup(requests.get(url1).text)\n",
    "        \n",
    "        if soup.find('table',{'border':'0'}) is None: # we find no results \n",
    "            break\n",
    "        \n",
    "        resp=requests.get(url1, headers={'User-Agent': 'anything'})\n",
    "\n",
    "        if resp.status_code==200:\n",
    "\n",
    "            for a in soup.find_all('a'): # 'tr',{'valign':'top'}): # get the whole content of the webpage: download pages or subpages containing \n",
    "\n",
    "                # 'a' looks like: '<a href=\"https://www.midiworld.com/files/123/\">The Association</a>'\n",
    "                a_formulation_str = str(a).lower()\n",
    "\n",
    "                if searched_artist in a_formulation_str:\n",
    "\n",
    "                    url_artist = str(a['href'])\n",
    "                    soup_artist = BeautifulSoup(requests.get(url_artist).text)\n",
    "\n",
    "                    for li in soup_artist.find_all('li') : # in them the song titles are saved\n",
    "\n",
    "                        if searched_song in str(li).lower(): \n",
    "                            for download_info in li.find_all('a'):\n",
    "                                download_url = download_info['href']\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                if day_limit_counter < 500:\n",
    "                                    url_check = webpage_virus_check(download_url)\n",
    "\n",
    "                                    if url_check > -1: # url could be suspicious but don't have to be\n",
    "                                        path_file_updated = download(download_url, download_path_mp3code, 'midiworldcom')\n",
    "\n",
    "                                        if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                                            # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                                            os.remove(path_file_updated) # delete the unneeded file\n",
    "                                        \n",
    "                                        elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                                            file_virus_check(path_file_updated)\n",
    "\n",
    "                                        elif url_check == 0 and day_limit_counter >= 500:\n",
    "                                            with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                                f.write(f'{search_term} midiworldcom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                                            return -1\n",
    "                                    else:\n",
    "                                        with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                                            f.write(f'midiworldcom {search_term} {download_url}\\n')\n",
    "                                else:\n",
    "                                    with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                        f.write(f'{search_term} midiworldcom\\n unfinished download \\n {download_url}')\n",
    "                                    return -1                                \n",
    "                                \n",
    "                                # downloaded\n",
    "                            break\n",
    "\n",
    "        else:\n",
    "            answer()\n",
    "\n",
    "    return\n",
    "\n",
    "#midiworldcom(searched_artist = 'The Association', searched_song = 'Along Comes Mary',download_path_mp3code='tester/association_idmp.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Germany Frankfurt Wurstchen (UDP:443)\n",
      "Firewall Enabled\n",
      "Connected to Germany Frankfurt Wurstchen\n",
      "Your IP changed from 45.87.212.23 to 149.36.50.7\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:183:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:395:5\nelement.find/</<@chrome://remote/content/marionette/element.sys.mjs:134:16\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8374/518321882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m#midisfreecom(search_term = 'shakira hips dont lie',download_path_mp3code='tester/hips_idmp.mid')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mmidisfreecom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'nirvana blew'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload_path_mp3code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tester/freemidiUMBAU_idmp.mid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_8374/518321882.py\u001b[0m in \u001b[0;36mmidisfreecom\u001b[0;34m(search_term, download_path_mp3code)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# midi = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, \"download\"))) # wait exactly 20 seconds #This is a dummy element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, ignored_exceptions=[ElementNotVisibleException, ElementNotSelectableException])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mmidi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_to_be_clickable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"//a[@id='download']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# wait at most 30 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mday_limit_counter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/support/wait.py\u001b[0m in \u001b[0;36muntil\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:183:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:395:5\nelement.find/</<@chrome://remote/content/marionette/element.sys.mjs:134:16\n"
     ]
    }
   ],
   "source": [
    "midisfreecom_download_counter = 10\n",
    "def midisfreecom(search_term:str, download_path_mp3code:str):\n",
    "    '''type: searches for single midi files that are returned by webpage'''\n",
    "    \n",
    "    # the target we want to open  \n",
    "    search_term = search_term.replace(' ', '+').replace('&','and').replace(\"'\",\"\").replace('.','+').replace('!','').replace('?','')\n",
    "    url='https://midisfree.com/search/?search=' + search_term# single_search #'http://www.hindustantimes.com/top-news'\n",
    "    global day_limit_counter, midisfreecom_download_counter\n",
    "    midisfreecom_download_counter = 10 # every time midisfreecom() executed change vpn location \n",
    "    # in lines below;\n",
    "    # newly added code\n",
    "    \n",
    "    full_path = os.path.abspath(download_path_mp3code)\n",
    "    wished_file_name = full_path.split('/')[-1]\n",
    "    download_path = full_path.replace(wished_file_name, '')\n",
    "\n",
    "    # needed for selenium:\n",
    "    option = webdriver.FirefoxOptions()\n",
    "    option.headless = True # GUI does not open, but navigation through web suceeds\n",
    "    # determine where to save the downloaded files\n",
    "    #0 means to download to the desktop, 1 means to download to the default \"Downloads\" directory, 2 means to use the directory\n",
    "    option.set_preference(\"browser.download.folderList\", 2) \n",
    "    option.set_preference(\"browser.download.dir\", download_path)\n",
    "    \n",
    "    \n",
    "    driver = webdriver.Firefox(options=option)\n",
    "    driver.get(url)\n",
    "\n",
    "    links_to_song_versions = driver.find_element(By.CLASS_NAME, \"row\").find_elements(By.TAG_NAME, 'a')\n",
    "    \n",
    "    collector = [i.get_attribute('href') for i in links_to_song_versions]\n",
    "    collector = set(collector)\n",
    "\n",
    "    for url_page_song in collector:\n",
    "        \n",
    "        # driver.get(url_page_song)\n",
    "\n",
    "        if midisfreecom_download_counter >= 4: # download limit per day: 4 files\n",
    "            os.system(\"windscribe connect\") # change IP\n",
    "            # driver.quit()\n",
    "            driver = webdriver.Firefox(options=option)\n",
    "            # driver.refresh()\n",
    "            midisfreecom_download_counter = 0\n",
    "\n",
    "        driver.get(url_page_song)\n",
    "\n",
    "        # midi = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, \"download\"))) # wait exactly 20 seconds #This is a dummy element\n",
    "        wait = WebDriverWait(driver, 30, poll_frequency=1)#, ignored_exceptions=[ElementNotVisibleException, ElementNotSelectableException])\n",
    "        midi = wait.until(EC.element_to_be_clickable((By.XPATH, \"//a[@id='download']\"))) # wait at most 30 seconds\n",
    "        \n",
    "        if day_limit_counter < 500:\n",
    "            url_check = webpage_virus_check(url_page_song) \n",
    "            print('url_check done')\n",
    "            if url_check > -1: # url could be suspicious but don't have to be\n",
    "                try:\n",
    "                    midi.click()\n",
    "                    print(midi)\n",
    "                except:\n",
    "                    if 'firefox' in driver.capabilities['browserName']:\n",
    "                        scroll_shim(driver, midi )\n",
    "                    # scroll_shim is just scrolling it into view, you still need to hover over it to click using an action chain.\n",
    "                    actions = ActionChains(driver)\n",
    "                    actions.move_to_element(midi )\n",
    "                    actions.click()\n",
    "                    actions.perform() # downloading                               \n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    \n",
    "                print('downloaded path with name',download_path_mp3code)\n",
    "                midisfreecom_download_counter += 1\n",
    "           \n",
    "                \n",
    "                path_file_updated = rename_downloaded_file(download_path_mp3code, 'midisfreecom')\n",
    "\n",
    "                if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                    # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                    os.remove(path_file_updated) # delete the unneeded file\n",
    " \n",
    "                elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                    file_virus_check(path_file_updated)\n",
    "                elif url_check == 0 and day_limit_counter >= 500:\n",
    "                    with open('where_we_stopped_collecting', 'a') as f:\n",
    "                        f.write(f'{search_term} midisfreecom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                    return -1\n",
    "            else:\n",
    "                with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                    f.write(f'midisfreecom {search_term} {url_page_song}\\n')\n",
    "        else:\n",
    "            with open('where_we_stopped_collecting', 'a') as f:\n",
    "                f.write(f'{search_term} midisfreecom\\n unfinished download \\n {url_page_song}')\n",
    "            return -1\n",
    "        \n",
    "    return\n",
    "    \n",
    "#midisfreecom(search_term = 'shakira hips dont lie',download_path_mp3code='tester/hips_idmp.mid')\n",
    "#midisfreecom(search_term = 'nirvana blew',download_path_mp3code='tester/freemidiUMBAU_idmp.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/c/Schreibtisch/ba_08102022/stage1_data_collecting_phase/webscraping/tester/\n"
     ]
    }
   ],
   "source": [
    "def cpratocom(search_term:str, download_path_mp3code:str):\n",
    "    '''DOWNLOAD\n",
    "    search_term: artist song \n",
    "    type: searches for single midi files that are returned by webpage. \n",
    "    When webpage does not find result it returns \"No MIDI files found.\" '''\n",
    "    \n",
    "    global day_limit_counter\n",
    "    \n",
    "    # the target we want to open  \n",
    "    search_term = search_term.replace(' ', '-').replace('&','and').replace(\"'\",\"\").replace('!','').replace('?','')\n",
    "    url='https://www.cprato.com/en/midi/search/' + search_term# single_search #'http://www.hindustantimes.com/top-news'\n",
    "      \n",
    "    #open with GET method\n",
    "    resp=requests.get(url, headers={'User-Agent': 'anything'})\n",
    "\n",
    "    if resp.status_code==200: # webpage can be opened\n",
    "\n",
    "        soup=BeautifulSoup(resp.text,'html.parser')   \n",
    "        \n",
    "        for a in soup.find_all('a'):\n",
    "            \n",
    "            if 'Free Download' in str(a): # we find the download link\n",
    "                download_url1 = a['href']\n",
    "                download_url = 'https://www.cprato.com' + download_url1                \n",
    "            \n",
    "                full_path = os.path.abspath(download_path_mp3code)\n",
    "                wished_file_name = full_path.split('/')[-1]\n",
    "                download_path = full_path.replace(wished_file_name, '')\n",
    "                \n",
    "                if day_limit_counter < 500:\n",
    "                    \n",
    "                    # needed for selenium:\n",
    "                    option = webdriver.FirefoxOptions()\n",
    "                    option.headless = True # GUI does not open, but navigation through web suceeds\n",
    "                    # determine where to save the downloaded files\n",
    "                    #0 means to download to the desktop, 1 means to download to the default \"Downloads\" directory, 2 means to use the directory\n",
    "                    option.set_preference(\"browser.download.folderList\", 2) \n",
    "                    option.set_preference(\"browser.download.dir\", download_path)\n",
    "\n",
    "                    \n",
    "                    url_check = webpage_virus_check(download_url)\n",
    "\n",
    "                    if url_check > -1: # url could be suspicious but don't have to be\n",
    "                        \n",
    "                        driver = webdriver.Firefox(options=option)\n",
    "                        driver.get(download_url)\n",
    "                        time.sleep(6)\n",
    "                        path_file_updated = rename_downloaded_file(download_path_mp3code, 'cpratocom')\n",
    "\n",
    "                        if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                            # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                            os.remove(path_file_updated) # delete the unneeded file\n",
    "                        \n",
    "                        elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                            file_virus_check(path_file_updated)\n",
    "\n",
    "                        elif url_check == 0 and day_limit_counter >= 500:\n",
    "                            with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                f.write(f'{search_term} cpratocom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                            return -1\n",
    "                    else:\n",
    "                        with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                            f.write(f'cpratocom {search_term} {download_url}\\n')\n",
    "                else:\n",
    "                    with open('where_we_stopped_collecting', 'a') as f:\n",
    "                        f.write(f'{search_term} cpratocom\\n unfinished download \\n {download_url}')\n",
    "                    return -1\n",
    "                \n",
    "                break\n",
    "        \n",
    "    else:\n",
    "        answer()\n",
    "    return\n",
    "\n",
    "#cpratocom(search_term = 'alan walker faded',download_path_mp3code='tester/walkerFaded_idmp.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#copy old\n",
    "nonstop2kcom_download_counter = 2 # counts how often we downloaded from nonstop2k.com\n",
    "\n",
    "def nonstop2kcom(search_term:str,download_path_mp3code:str):\n",
    "    '''DOWNLOAD, \n",
    "    \n",
    "    search_term: artist song \n",
    "    type: searches for single midi files that are returned by webpage. When webpage does not find result\n",
    "    it returns \"No MIDI files found.\".\n",
    "    \n",
    "    ARGUMENT download_path_mp3code: Be aware that there have to be a '?' in the path,\n",
    "    e. g. MP3codeFolderName/?/FileName.mid,\n",
    "    The '?' defines if we have a full or demo version. This function finds it out.\n",
    "    \n",
    "    We only open the webpage when we found the a song for FREE. \n",
    "    This is reached with the end part of the url.'''\n",
    "\n",
    "    global day_limit_counter, nonstop2kcom_download_counter\n",
    "    # nonstop2kcom_download_counter = 2 # do this when problems with limited downloading\n",
    "    \n",
    "    # the target we want to open  \n",
    "    search_term1 = search_term.replace(' ', '+').replace('&','and').replace(\"'\",\"\").replace('!','').replace('?','')\n",
    "\n",
    "    url='https://www.nonstop2k.com/midi-files/search.php?keywords=' + search_term1 + '&send=1&type=all&kid=0&d=0&pm=2&f=0&act=3' # to get only the free songs# single_search #'http://www.hindustantimes.com/top-news'\n",
    "\n",
    "    global nonstop2kcom_download_counter \n",
    "    #open with GET method\n",
    "    resp=requests.get(url, headers={'User-Agent': 'anything'})\n",
    "\n",
    "    if resp.status_code==200: # webpage can be opened\n",
    "        \n",
    "        soup=BeautifulSoup(resp.text,'html.parser')    \n",
    "      \n",
    "        # results is the list which contains all the text:\n",
    "        page_content = soup.find('div', {'class':'heroContainer'}) # returns None when we found a result\n",
    "        \n",
    "        if page_content is None: # we found a result\n",
    "            search_term2 = search_term.replace(' ', '-')\n",
    "            search_term2 = search_term2.lower()\n",
    "            for a in soup.find_all('a'):\n",
    "\n",
    "                try:\n",
    "                    if search_term2 in a['href'].lower() and 'midi.html' in a['href'].lower():\n",
    "\n",
    "                        url2 = 'https://www.nonstop2k.com' + a['href'][2:]\n",
    "                        # url2 gives us the webpage with the song title and \n",
    "                        # download link\n",
    "                                               \n",
    "                        resp2=requests.get(url2, headers={'User-Agent': 'anything'})\n",
    "                        soup2=BeautifulSoup(resp2.text,'html.parser') \n",
    "                        \n",
    "                        \n",
    "                        # find out if we have a demo or full version available:\n",
    "                        for i in soup2.find('div', {'id':'midifeatures'}).find_all('span'):\n",
    "                            try:\n",
    "                                if \"midiNotFull\" in i['class']: # then we have a demo of the song\n",
    "                                    download_path_mp3code = download_path_mp3code.replace('?', 'demo')\n",
    "                                    break\n",
    "                                elif \"midiFull\" in i['class']: # then we get the full song\n",
    "                                    download_path_mp3code = download_path_mp3code.replace('?', 'full')\n",
    "                                    break\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "                        \n",
    "                        # download the found midi file:\n",
    "                      \n",
    "                        if day_limit_counter < 500:\n",
    "\n",
    "                            full_path = os.path.abspath(download_path_mp3code)\n",
    "                            wished_file_name = full_path.split('/')[-1]\n",
    "                            download_path = full_path.replace(wished_file_name, '')\n",
    "\n",
    "                            # Overgo download limit of 2 files per day:\n",
    "                            if nonstop2kcom_download_counter == 2:\n",
    "                                os.system(\"windscribe connect\")\n",
    "                                nonstop2kcom_download_counter = 0\n",
    "\n",
    "                            # needed for selenium:\n",
    "\n",
    "                            option = webdriver.FirefoxOptions()\n",
    "                            option.headless = True # GUI does not open, but navigation through web suceeds\n",
    "                            # determine where to save the downloaded files\n",
    "                            #0 means to download to the desktop, 1 means to download to the default \"Downloads\" directory, 2 means to use the directory\n",
    "                            option.set_preference(\"browser.download.folderList\", 2) \n",
    "                            option.set_preference(\"browser.download.dir\", download_path)\n",
    "\n",
    "                            \n",
    "                            driver = webdriver.Firefox(options=option)\n",
    "                            driver.get(url2)\n",
    "\n",
    "                            download_ele = driver.find_element(By.ID, 'midiDlB1')\n",
    "                                                     \n",
    "                            url_check = webpage_virus_check(url2) \n",
    "                           \n",
    "                            if url_check > -1: # url could be suspicious but don't have to be\n",
    "\n",
    "                                if 'firefox' in driver.capabilities['browserName']:\n",
    "                                    scroll_shim(driver, download_ele )\n",
    "                                # scroll_shim is just scrolling it into view, you still need to hover over it to click using an action chain.\n",
    "                                actions = ActionChains(driver)\n",
    "                                actions.move_to_element(download_ele )\n",
    "                                actions.click()\n",
    "                                actions.perform() # downloading                               \n",
    "                                nonstop2kcom_download_counter += 1\n",
    "                                \n",
    "                                time.sleep(1) # renaming works after waiting 1 second\n",
    "                                path_file_updated = rename_downloaded_file(download_path_mp3code, 'nonstop2kcom') \n",
    "\n",
    "                                if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                                    # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                                    os.remove(path_file_updated) # delete the unneeded file\n",
    "                                \n",
    "                                elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                                    file_virus_check(path_file_updated)\n",
    "\n",
    "                                elif url_check == 0 and day_limit_counter >= 500:\n",
    "                                    with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                        f.write(f'{search_term} nonstop2kcom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                                    return -1\n",
    "                            else:\n",
    "                                with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                                    f.write(f'nonstop2kcom {search_term} {url2}\\n')\n",
    "                        else:\n",
    "                            with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                f.write(f'{search_term} nonstop2kcom\\n unfinished download \\n {url2}')\n",
    "                            return -1\n",
    "                        \n",
    "                        return\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "    else:\n",
    "        answer()\n",
    "        \n",
    "    return\n",
    "\n",
    "# nonstop2kcom(search_term = 'lady gaga hair',download_path_mp3code='tester/?/nonstop_idmp.mid')\n",
    "# nonstop2kcom(search_term = 'queen bohemian rhapsody',download_path_mp3code='tester/?/nonstop_idmp.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partnersinrhymecom(searched_artist:str, searched_song:str, download_path_mp3code):\n",
    "    ''' DOWNLOAD!\n",
    "    searched_artist: type in artist name\n",
    "    type: want to find artist via url. when page gives back 404, we know that artist not exists for this\n",
    "    webpage. Same for song.\n",
    "    '''\n",
    "    \n",
    "    global day_limit_counter\n",
    "    \n",
    "    # the target we want to open  \n",
    "    searched_artist = searched_artist.lower()\n",
    "    searched_artist = searched_artist.replace(' ', '_')\n",
    "    \n",
    "    searched_song = searched_song.replace(' ', '_').replace('&','and').replace(\"'\",\"\").replace('!','').replace('?','')\n",
    "    searched_song = searched_song.lower()\n",
    "        \n",
    "    download_url = f'https://composerconnection.com/midi1/pop_rock/{searched_artist}/{searched_song}.mid'\n",
    "    # url found out with soup.find_all() function\n",
    "    \n",
    "    resp=requests.get(download_url, headers={'User-Agent': 'anything'})\n",
    "        \n",
    "    if resp.status_code==200: # webpage can be opened\n",
    "        # response 404 when webpage with given artist name and song does not exist!\n",
    "        \n",
    "        if day_limit_counter < 500:\n",
    "            url_check = webpage_virus_check(download_url)\n",
    "\n",
    "            if url_check > -1: # url could be suspicious but don't have to be\n",
    "                path_file_updated = download(download_url, download_path_mp3code, 'partnersinrhymecom')\n",
    "                \n",
    "                if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                    # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                    os.remove(path_file_updated) # delete the unneeded file\n",
    "\n",
    "                elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                    file_virus_check(path_file_updated)\n",
    "\n",
    "                elif url_check == 0 and day_limit_counter >= 500:\n",
    "                    with open('where_we_stopped_collecting', 'a') as f:\n",
    "                        f.write(f'{search_term} partnersinrhymecom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                    return -1\n",
    "            else:\n",
    "                with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                    f.write(f'partnersinrhymecom{search_term} {download_url}\\n')\n",
    "        else:\n",
    "            with open('where_we_stopped_collecting', 'a') as f:\n",
    "                f.write(f'{search_term} partnersinrhymecom\\n unfinished download \\n {download_url}')\n",
    "            return -1\n",
    "       \n",
    "    return\n",
    "\n",
    "# partnersinrhymecom(searched_artist = 'nirvana',searched_song='blew',download_path_mp3code='tester/BLEW_idmp.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mididbcom(searched_artist:str, searched_song:str, download_path_mp3code:str):\n",
    "    '''\n",
    "    searched_artist: type in artist name\n",
    "    type: want to find artist + song via url. when page gives back 404, we know that artist + song\n",
    "    not exists for this webpage\n",
    "    '''\n",
    "    \n",
    "    global day_limit_counter\n",
    "    \n",
    "    # the target we want to open  \n",
    "    searched_artist = searched_artist.replace(' ', '-').lower()\n",
    "    searched_song = searched_song.replace(' ', '-').replace('&','and').replace(\"'\",\"\").replace('!','').replace('?','').lower()\n",
    "    \n",
    "    \n",
    "    url1 = 'https://www.mididb.com/'\n",
    "    url2 = '-midi/'# single_search #'http://www.hindustantimes.com/top-news'\n",
    "    url = url1 + searched_artist + '/'+ searched_song + url2 \n",
    "\n",
    "    #open with GET method:\n",
    "    resp=requests.get(url, headers={'User-Agent': 'anything'})\n",
    "        \n",
    "    if resp.status_code==200: # webpage can be opened\n",
    "        # response 404 when webpage with given artist + song does not exist!\n",
    "\n",
    "        soup = BeautifulSoup(requests.get(url).text)\n",
    "        for a in soup.find_all('a'):\n",
    "            try:\n",
    "                if 'download' in a['href']:\n",
    "                    \n",
    "                    download_url = a['href']\n",
    "                    \n",
    "                    if day_limit_counter < 500:\n",
    "                        url_check = webpage_virus_check(download_url)\n",
    "\n",
    "                        if url_check > -1: # url could be suspicious but don't have to be\n",
    "                            path_file_updated = download(download_url, download_path_mp3code, 'mididbcom')\n",
    "\n",
    "                            if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                                # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                                os.remove(path_file_updated) # delete the unneeded file\n",
    "                            \n",
    "                            elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                                file_virus_check(path_file_updated)\n",
    "\n",
    "                            elif url_check == 0 and day_limit_counter >= 500:\n",
    "                                with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                    f.write(f'{search_term} mididbcom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                                return -1\n",
    "                        else:\n",
    "                            with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                                f.write(f'mididbcom {search_term} {download_url}\\n')\n",
    "                    else:\n",
    "                        with open('where_we_stopped_collecting', 'a') as f:\n",
    "                            f.write(f'{search_term} mididbcom\\n unfinished download \\n {download_url}')\n",
    "                        return -1                   \n",
    "                    \n",
    "                    break\n",
    "            except:\n",
    "                pass\n",
    "                              \n",
    "    return\n",
    "\n",
    "# mididbcom(searched_artist = 'nirvana',searched_song='come as you are',download_path_mp3code='tester/mididbcom_idmp.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "miditune_download_counter = 43\n",
    "def miditunecom(searched_artist:str, searched_song:str, download_path_mp3code:str): \n",
    "    ''' DOWNLOAD\n",
    "    Has a download limit of 42 files per day. Therefore, we simply change the IP address when exceeding\n",
    "    this limit.\n",
    "    type: the url does not change here when we search for a song on the webpage. Therefore, we have a look at\n",
    "    all download files of this webpage!'''\n",
    "    \n",
    "    global day_limit_counter\n",
    "    \n",
    "    global miditune_download_counter\n",
    "    # miditune_download_counter = 43 # activate this line when problems with limited daily download amount\n",
    "    \n",
    "    full_path = os.path.abspath(download_path_mp3code)\n",
    "    wished_file_name = full_path.split('/')[-1]\n",
    "    download_path = full_path.replace(wished_file_name, '')\n",
    "    \n",
    "    # needed for selenium:\n",
    "    option = webdriver.FirefoxOptions()\n",
    "    option.headless = True # GUI does not open, but navigation through web suceeds\n",
    "    # determine where to save the downloaded files\n",
    "    #0 means to download to the desktop, 1 means to download to the default \"Downloads\" directory, 2 means to use the directory\n",
    "    option.set_preference(\"browser.download.folderList\", 2) \n",
    "    option.set_preference(\"browser.download.dir\", download_path)\n",
    "    \n",
    "    searched_song = searched_song.replace('&','and').replace(\"'\",\"\").replace('!','').replace('?','').lower()\n",
    "    searched_artist = searched_artist.lower()\n",
    "    searched_string = searched_artist + ' - ' + searched_song\n",
    "                \n",
    "    searched_song_strich = searched_song.replace(' ', '-')\n",
    "    searched_artist_strich = searched_artist.replace(' ', '-')\n",
    "    url_alphabet_list = f'http://miditune.com/list/midi-{searched_artist[0].upper()}.html' # found out via soup\n",
    "    resp=requests.get(url_alphabet_list, headers={'User-Agent': 'anything'})\n",
    "    if resp.status_code==200:\n",
    "        \n",
    "        soup = BeautifulSoup(requests.get(url_alphabet_list).text)\n",
    "        \n",
    "        # Loop over all artist-song-combis to get all versions of one song:\n",
    "        for aa in soup.find_all('a'):\n",
    "\n",
    "            if searched_song in str(aa).lower() and searched_artist in str(aa).lower():\n",
    "                    try:\n",
    "                        next_url_part = aa['href'] # page where we will find \n",
    "                        important = next_url_part.split('/')[3]\n",
    "                        next_url = 'http://download.midimi.org/' + important\n",
    "                    \n",
    "                        driver = webdriver.Firefox(options=option)\n",
    "                        driver.get(next_url)\n",
    "                        find_link_to_download = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "                     \n",
    "                        # Loop over all possible 'a' html parts to find the download link of our song:\n",
    "                        for e in find_link_to_download:\n",
    "                            \n",
    "                            searched_string2 = searched_string + '.mid'\n",
    "                           \n",
    "                        \n",
    "                            if '#' in str(e.get_attribute(\"href\")) and searched_song in str(e.text).lower() and searched_artist in str(e.text).lower() and '.mid' in str(e.text).lower():\n",
    "                                download_url =  e.get_attribute(\"href\")\n",
    "\n",
    "                                if miditune_download_counter > 42: # download limit of miditune.com\n",
    "                                    # is by 42 files per day.\n",
    "                                    # Therefore, simply change IP address to get access to even\n",
    "                                    # more files.\n",
    "                                    driver.close()\n",
    "                                    os.system(\"windscribe connect\") # change IP\n",
    "                                   \n",
    "                                    driver = webdriver.Firefox(options=option)\n",
    "                                    driver.get(next_url)\n",
    "                                    \n",
    "                                    find_link_to_download = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "                                    for e2 in find_link_to_download:\n",
    "                                  \n",
    "                                        if '#' in str(e2.get_attribute(\"href\")) and searched_song in str(e2.text).lower() and searched_artist in str(e2.text).lower() and '.mid' in str(e2.text).lower():\n",
    "                                            \n",
    "                                            if day_limit_counter < 500:\n",
    "                                                url_check = webpage_virus_check(download_url)\n",
    "                                                \n",
    "                                                if url_check > -1: # url could be suspicious but don't have to be\n",
    "                                                    e2.click() # click on download link\n",
    "                                                   \n",
    "                                                    path_file_updated =  rename_downloaded_file(download_path_mp3code, 'miditunecom')\n",
    "                                                    \n",
    "                                                    if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                                                        # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                                                        os.remove(path_file_updated) # delete the unneeded file\n",
    "                                                    \n",
    "                                                    elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                                                        file_virus_check(path_file_updated)\n",
    "\n",
    "                                                    elif url_check == 0 and day_limit_counter >= 500:\n",
    "                                                        with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                                            f.write(f'{search_term} miditunecom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                                                        return -1\n",
    "                                                else:\n",
    "                                                    with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                                                        f.write(f'miditunecom {search_term} {next_url}\\n')\n",
    "                                            else:\n",
    "                                                with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                                    f.write(f'{search_term} miditunecom\\n unfinished download \\n {next_url}')\n",
    "                                                return -1\n",
    "\n",
    "                                            miditune_download_counter = 1\n",
    "                                            break\n",
    "                                else:\n",
    "                                    \n",
    "                                    if day_limit_counter < 500:\n",
    "                                        \n",
    "                                        url_check = webpage_virus_check(download_url)\n",
    "                                       \n",
    "                                        if url_check > -1: # url could be suspicious but don't have to be\n",
    "                                            e.click() # click on download link\n",
    "                                            \n",
    "                                            path_file_updated =  rename_downloaded_file(download_path_mp3code, 'miditunecom')\n",
    "                                          \n",
    "                                            if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                                                # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                                                os.remove(path_file_updated) # delete the unneeded file\n",
    "       \n",
    "                                            elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                                                file_virus_check(path_file_updated)\n",
    "\n",
    "                                            elif url_check == 0 and day_limit_counter >= 500:\n",
    "                                                with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                                    f.write(f'{search_term} miditunecom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                                                return -1\n",
    "                                        else:\n",
    "                                            with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                                                f.write(f'miditunecom {search_term} {next_url}\\n')\n",
    "                                    else:\n",
    "                                        with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                            f.write(f'{search_term} miditunecom\\n unfinished download \\n {next_url}')\n",
    "                                        return -1 \n",
    "                                                                        \n",
    "                                    miditune_download_counter += 1\n",
    "                                    driver.close()\n",
    "                                    # downloaded\n",
    "                                break                                 \n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "      \n",
    "    else:\n",
    "        answer()\n",
    "\n",
    "    return                                    \n",
    "                                    \n",
    "# miditunecom(searched_artist='nirvana', searched_song='come as you are', download_path_mp3code='tester/miditune_wishname.mid')#download_path='/home/c/Schreibtisch/ba/yo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvbeethovenfr(searched_artist:str):\n",
    "    '''\n",
    "    NO download, only URL opening.\n",
    "    \n",
    "    This webpage only contains Beethoven.\n",
    "    type: only look if the searched artist is Beethoven. When that is the case,\n",
    "    open the webpage\n",
    "\n",
    "    '''\n",
    "    \n",
    "    searched_artist = searched_artist.lower()\n",
    "    if searched_artist == 'beethoven':\n",
    "\n",
    "       # url = \"http://www.lvbeethoven.fr/Oeuvres/Music-Midi-Mp3-Symphonies.html\"\n",
    "        url = 'http://www.lvbeethoven.fr/Midi/index_En.html'\n",
    "        resp=requests.get(url, headers={'User-Agent': 'anything'})\n",
    "\n",
    "        if resp.status_code==200:\n",
    "            \n",
    "            open_(url)\n",
    "           \n",
    "        else:\n",
    "            answer()\n",
    "\n",
    "#lvbeethovenfr(searched_artist='beethoven')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rppmfcom(searched_artist:str, searched_song:str, download_path_mp3code:str):\n",
    "    ''' DIRECT DOWNLOAD\n",
    "    searched_artist: type in artist name\n",
    "    type: want to find artist + song via url. when page gives back 404, we know that artist + song\n",
    "    not exists for this webpage\n",
    "    '''\n",
    "    \n",
    "    global day_limit_counter\n",
    "    \n",
    "    # the target we want to open  \n",
    "    searched_artist = searched_artist.replace(' ', '_')\n",
    "    searched_artist = searched_artist.lower()\n",
    "    searched_song = searched_song.replace(' ', '_').replace('&','and').replace(\"'\",\"\").replace('!','').replace('?','')\n",
    "    searched_song = searched_song.lower()\n",
    "    \n",
    "    url1 = 'http://www.rppmf.com/'\n",
    "    url2 = '.htm'# single_search #'http://www.hindustantimes.com/top-news'\n",
    "    url = url1 + searched_artist + url2 \n",
    "    \n",
    "    #open with GET method\n",
    "    \n",
    "    resp=requests.get(url, headers={'User-Agent': 'anything'})\n",
    "\n",
    "    if resp.status_code==200: # webpage can be opened # artist exists\n",
    "        # response 404 when webpage with given artist does not exist!\n",
    "\n",
    "        soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "        for a in soup.find_all('a'): # get the whole content of the webpage: download pages or subpages containing \n",
    "        # further downloads\n",
    "       \n",
    "            try:\n",
    "                midi_path = a['href']\n",
    "                if '.mid' in midi_path and searched_song in midi_path: # download the midi file!\n",
    "                    download_url = url1 + midi_path                  \n",
    "                    \n",
    "                    if day_limit_counter < 500:\n",
    "                        url_check = webpage_virus_check(download_url)\n",
    "\n",
    "                        if url_check > -1: # url could be suspicious but don't have to be\n",
    "                            path_file_updated = download(download_url, download_path_mp3code, 'rppmfcom')\n",
    "                            \n",
    "                            if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                                # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                                os.remove(path_file_updated) # delete the unneeded file\n",
    "                            \n",
    "                            elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                                file_virus_check(path_file_updated)\n",
    "\n",
    "                            elif url_check == 0 and day_limit_counter >= 500:\n",
    "                                with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                    f.write(f'{search_term} rppmfcom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                                return -1\n",
    "                        else:\n",
    "                            with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                                f.write(f'rppmfcom {search_term} {download_url}\\n')\n",
    "                    else:\n",
    "                        with open('where_we_stopped_collecting', 'a') as f:\n",
    "                            f.write(f'{search_term} rppmfcom\\n unfinished download \\n {download_url}')\n",
    "                        return -1\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return\n",
    "\n",
    "#rppmfcom(searched_artist = 'coldplay',searched_song='spies',download_path_mp3code='tester/spies_idmp.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metalmidigrahamdowneycom(searched_artist:str, searched_song:str, download_path_mp3code:str):\n",
    "    ''' DIRECT DOWNLOAD\n",
    "    searched_artist: type in artist name\n",
    "    type: want to find artist + song via url. when page gives back 404, we know that artist + song\n",
    "    not exists for this webpage\n",
    "    '''\n",
    "    \n",
    "    global day_limit_counter\n",
    "    \n",
    "    # the target we want to open  \n",
    "\n",
    "    searched_artist = searched_artist.lower()\n",
    "  \n",
    "    searched_song = searched_song.replace('&','and').replace(\"'\",\"\").replace('!','').replace('?','').lower()\n",
    "    \n",
    "    url1 = 'http://metal-midi.grahamdowney.com/'\n",
    "    url2 = 'midi.html'# single_search #'http://www.hindustantimes.com/top-news'\n",
    "    url = url1 + url2  # general urls\n",
    "    \n",
    "    #open with GET method:\n",
    "    resp=requests.get(url, headers={'User-Agent': 'anything'}) \n",
    "        \n",
    "    if resp.status_code==200: # webpage can be opened # artist exists\n",
    "        # response 404 when webpage with given artist does not exist!\n",
    "\n",
    "        soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "        for a in soup.find_all('a'): # get the whole content of the webpage: download pages or subpages containing \n",
    "        # further downloads\n",
    "       \n",
    "            try:\n",
    "                midi_path = a['href']\n",
    "                midi_path_name = midi_path.lower()\n",
    "                if '.mid' in midi_path_name and searched_artist in midi_path_name and searched_song in midi_path_name: # download the midi file!\n",
    "                    download_url = url1 + midi_path\n",
    "           \n",
    "                    if day_limit_counter < 500:\n",
    "                        url_check = webpage_virus_check(download_url)\n",
    "\n",
    "                        if url_check > -1: # url could be suspicious but don't have to be\n",
    "                            path_file_updated = download(download_url, download_path_mp3code, 'metalmidigrahamdowneycom')\n",
    "                            \n",
    "                            if 'text' in magic.from_file(path_file_updated): # can be HTML code or text file\n",
    "                                # like 'You already have reached download limit.' or it is a copy of an existing file\n",
    "                                os.remove(path_file_updated) # delete the unneeded file\n",
    "                            \n",
    "                            elif url_check == 0 and day_limit_counter < 500: # url is more or less suspicious\n",
    "                                file_virus_check(path_file_updated)\n",
    "\n",
    "                            elif url_check == 0 and day_limit_counter >= 500:\n",
    "                                with open('where_we_stopped_collecting', 'a') as f:\n",
    "                                    f.write(f'{search_term} metalmidigrahamdowneycom \\n unfinished file virus check \\n {path_file_updated}')\n",
    "                                return -1\n",
    "                        else:\n",
    "                            with open('found_threat_info_undownloaded', 'a') as f:\n",
    "                                f.write(f'metalmidigrahamdowneycom {search_term} {download_url}\\n')\n",
    "                    else:\n",
    "                        with open('where_we_stopped_collecting', 'a') as f:\n",
    "                            f.write(f'{search_term} metalmidigrahamdowneycom\\n unfinished download \\n {download_url}')\n",
    "                        return -1            \n",
    "            \n",
    "            except: \n",
    "                pass\n",
    "            \n",
    "    else:\n",
    "        answer()\n",
    "\n",
    "    return\n",
    "\n",
    "#metalmidigrahamdowneycom(searched_artist = 'chinese man',searched_song='ive got that tune',download_path_mp3code='tester/fail_idmp.mid')\n",
    "#metalmidigrahamdowneycom(searched_artist = 'Type O Negative',searched_song='Black No.1',download_path_mp3code='tester/blockno1_idmp.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding all functions together and go through data set\n",
    "Go through each sample and download from webpages above with help of webpage functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_limit_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, type starting index in it:1\n",
      "https://bitmidi.com/Desiigner-Panda-mid\n",
      "a done\n",
      "b done\n",
      "200\n",
      "c done\n",
      "https://midisfree.com/search/?search=Desiigner+Panda\n",
      "/home/c/Schreibtisch/ba_08102022/stage1_data_collecting_phase/webscraping/midi-files/H_Desiigner_Panda/full/\n",
      "the midisfreedownloadcounter.com 10\n",
      "d done\n",
      "e done\n",
      "f done\n",
      "https://www.mididb.com/desiigner/panda-midi/\n",
      "<Response [404]>\n",
      "g done\n",
      "h done\n",
      "i done\n",
      "j done\n",
      "<Response [404]>\n",
      "http://www.rppmf.com/desiigner.htm\n",
      "k done\n",
      "l done\n",
      "1 -th row/song_artist done\n",
      "https://bitmidi.com/NAS-Doo-Rags-mid\n",
      "a done\n",
      "b done\n",
      "200\n",
      "c done\n",
      "https://midisfree.com/search/?search=NAS+Doo+Rags\n",
      "/home/c/Schreibtisch/ba_08102022/stage1_data_collecting_phase/webscraping/midi-files/H_NAS_DooRags/full/\n",
      "the midisfreedownloadcounter.com 10\n",
      "d done\n",
      "e done\n",
      "f done\n",
      "https://www.mididb.com/nas/doo-rags-midi/\n",
      "<Response [404]>\n",
      "g done\n",
      "h done\n",
      "i done\n",
      "j done\n",
      "<Response [404]>\n",
      "http://www.rppmf.com/nas.htm\n",
      "k done\n",
      "l done\n",
      "2 -th row/song_artist done\n",
      "https://bitmidi.com/DMX-X-Gon-Give-It-To-Ya-mid\n",
      "a done\n",
      "b done\n",
      "200\n",
      "c done\n",
      "https://midisfree.com/search/?search=DMX+X+Gon+Give+It+To+Ya\n",
      "/home/c/Schreibtisch/ba_08102022/stage1_data_collecting_phase/webscraping/midi-files/H_DMX_XGonGiv/full/\n",
      "the midisfreedownloadcounter.com 10\n",
      "d done\n",
      "e done\n",
      "f done\n",
      "https://www.mididb.com/dmx/x-gon-give-it-to-ya-midi/\n",
      "<Response [404]>\n",
      "g done\n",
      "h done\n",
      "i done\n",
      "j done\n",
      "<Response [404]>\n",
      "http://www.rppmf.com/dmx.htm\n",
      "k done\n",
      "l done\n",
      "3 -th row/song_artist done\n",
      "https://bitmidi.com/Xatar-Meine-Gro√üe-Liebe-mid\n",
      "a done\n",
      "b done\n",
      "200\n",
      "c done\n",
      "https://midisfree.com/search/?search=Xatar+Meine+Gro√üe+Liebe\n",
      "/home/c/Schreibtisch/ba_08102022/stage1_data_collecting_phase/webscraping/midi-files/H_Xatar_MeineGr/full/\n",
      "the midisfreedownloadcounter.com 10\n",
      "d done\n",
      "e done\n",
      "f done\n",
      "https://www.mididb.com/xatar/meine-gro√üe-liebe-midi/\n",
      "<Response [404]>\n",
      "g done\n",
      "h done\n",
      "i done\n",
      "j done\n",
      "<Response [404]>\n",
      "http://www.rppmf.com/xatar.htm\n",
      "k done\n",
      "l done\n",
      "4 -th row/song_artist done\n",
      "https://bitmidi.com/Biggie-Smalls-Hypnotize-mid\n",
      "a done\n",
      "b done\n",
      "200\n",
      "c done\n",
      "https://midisfree.com/search/?search=Biggie+Smalls+Hypnotize\n",
      "/home/c/Schreibtisch/ba_08102022/stage1_data_collecting_phase/webscraping/midi-files/H_BiggieSmalls_Hypnoti/full/\n",
      "the midisfreedownloadcounter.com 10\n",
      "d done\n",
      "e done\n",
      "f done\n",
      "https://www.mididb.com/biggie-smalls/hypnotize-midi/\n",
      "<Response [404]>\n",
      "g done\n",
      "h done\n",
      "i done\n",
      "j done\n",
      "<Response [404]>\n",
      "http://www.rppmf.com/biggie_smalls.htm\n",
      "k done\n",
      "l done\n",
      "5 -th row/song_artist done\n",
      "https://bitmidi.com/Salt-N-Pepa-Shoop-mid\n",
      "a done\n",
      "b done\n",
      "200\n",
      "c done\n",
      "https://midisfree.com/search/?search=Salt-N-Pepa+Shoop\n",
      "/home/c/Schreibtisch/ba_08102022/stage1_data_collecting_phase/webscraping/midi-files/H_Salt-N-Pepa_Shoop/full/\n",
      "the midisfreedownloadcounter.com 10\n",
      "d done\n",
      "e done\n",
      "f done\n",
      "https://www.mididb.com/salt-n-pepa/shoop-midi/\n",
      "<Response [404]>\n",
      "g done\n",
      "h done\n",
      "i done\n",
      "j done\n",
      "<Response [404]>\n",
      "http://www.rppmf.com/salt-n-pepa.htm\n",
      "k done\n",
      "l done\n",
      "6 -th row/song_artist done\n",
      "https://bitmidi.com/Prinz-Pi-Laura-mid\n",
      "a done\n",
      "b done\n",
      "200\n",
      "c done\n",
      "https://midisfree.com/search/?search=Prinz+Pi+Laura\n",
      "/home/c/Schreibtisch/ba_08102022/stage1_data_collecting_phase/webscraping/midi-files/H_PrinzPi_Laura/full/\n",
      "the midisfreedownloadcounter.com 10\n",
      "d done\n",
      "e done\n",
      "f done\n",
      "https://www.mididb.com/prinz-pi/laura-midi/\n",
      "<Response [404]>\n",
      "g done\n",
      "h done\n",
      "i done\n",
      "j done\n",
      "<Response [404]>\n",
      "http://www.rppmf.com/prinz_pi.htm\n",
      "k done\n",
      "l done\n",
      "7 -th row/song_artist done\n",
      "https://bitmidi.com/Black-Eyed-Peas-Where-Is-The-Love-mid\n",
      "a done\n",
      "ele <selenium.webdriver.remote.webelement.WebElement (session=\"72d0aba6-4158-4c09-94f4-1422b2c16ad4\", element=\"da788847-4525-460f-b9b5-85268406b6cf\")>\n",
      "/home/c/Schreibtisch/ba_08102022/stage1_data_collecting_phase/webscraping/midi-files/H_BlackEyedPeas_WhereIs/full/\n",
      "b done\n",
      "200\n",
      "c done\n",
      "https://midisfree.com/search/?search=Black+Eyed+Peas+Where+Is+The+Love\n",
      "/home/c/Schreibtisch/ba_08102022/stage1_data_collecting_phase/webscraping/midi-files/H_BlackEyedPeas_WhereIs/full/\n",
      "Connecting to Germany Frankfurt Wurstchen (UDP:443)\n",
      "Firewall Enabled\n",
      "Connected to Germany Frankfurt Wurstchen\n",
      "Your IP changed from 87.182.27.13 to 45.87.212.23\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:183:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:395:5\nelement.find/</<@chrome://remote/content/marionette/element.sys.mjs:134:16\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8374/3209754685.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmidiworldcom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearched_artist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_art\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearched_song\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_song\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload_path_mp3code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'midiworld_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcurr_search_term\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmidisfreecom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_search_term\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload_path_mp3code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'midisfreecom_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcurr_mp3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'the midisfreedownloadcounter.com'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidisfreecom_download_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'd done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8374/457212097.py\u001b[0m in \u001b[0;36mmidisfreecom\u001b[0;34m(search_term, download_path_mp3code)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# midi = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, \"download\"))) # wait exactly 20 seconds #This is a dummy element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, ignored_exceptions=[ElementNotVisibleException, ElementNotSelectableException])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mmidi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_to_be_clickable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"//a[@id='download']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# wait at most 30 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mday_limit_counter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/support/wait.py\u001b[0m in \u001b[0;36muntil\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:183:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:395:5\nelement.find/</<@chrome://remote/content/marionette/element.sys.mjs:134:16\n"
     ]
    }
   ],
   "source": [
    "col = small3.columns\n",
    "number = int(input('Please, type starting index in it:'))\n",
    "small4 = small3[number:] # start in the dataframe with the index+1 where we stopped downloading last time\n",
    "\n",
    "for ind, row in small4.iterrows():\n",
    "    curr_code = row[col[0]]\n",
    "    curr_mp3 =  row[col[1]]\n",
    "    curr_art =  row[col[2]]\n",
    "    curr_song =  row[col[3]]\n",
    "    curr_search_term =  row[col[4]]\n",
    "    curr_search_term2 =  row[col[5]]\n",
    "    \n",
    "    \n",
    "    day_limit_counter_old = day_limit_counter      \n",
    "    \n",
    "    download_path = 'midi-files/' + str(curr_mp3) + '/full/'\n",
    "    \n",
    "    download_path_demo = 'midi-files/' + str(curr_mp3) + '/demo/'\n",
    "    \n",
    "    # remove all files downloaded so far for the starting index to avoid duplicates:\n",
    "    if ind == number:\n",
    "        shutil.rmtree(download_path) # remove folder\n",
    "        os.makedirs(download_path) # create same folder but its empty now\n",
    "        \n",
    "        shutil.rmtree(download_path_demo)\n",
    "        os.makedirs(download_path_demo)\n",
    "        \n",
    "        path3a = os.path.join(download_path, 'webpageinfo.txt')\n",
    "        path4a = os.path.join(download_path_demo, 'webpageinfo.txt')\n",
    "        open(path3a,'w') # create file in which the related web pages shall be stored\n",
    "        open(path4a,'w')\n",
    "        \n",
    "        \n",
    "    \n",
    "    # handle beethoven page:\n",
    "    art_lower = curr_art.lower()\n",
    "    if art_lower == 'beethoven':\n",
    "        print(row)\n",
    "        print(f'folder: {curr_mp3}')\n",
    "        lvbeethovenfr(art_lower)\n",
    "        v = input('How many files did you download?')\n",
    "        day_limit_counter += int(v)\n",
    "        done = False\n",
    "        if int(v) == 0:\n",
    "            done = True\n",
    "        while not done:\n",
    "            name_mid = input('what is one of the filenames?[name/done]')\n",
    "            if name_mid == 'done':\n",
    "                done = True\n",
    "            else:\n",
    "                path_name = 'midi-files/' + curr_mp3 + '/full/' + f'{name_mid}'\n",
    "                file_virus_check(path_name)\n",
    "                \n",
    "        \n",
    "    # getting remaining pages with automatic download:\n",
    "    a=bitmidicom(search_term = curr_search_term, song_name=curr_song, download_path_mp3code=(download_path+'bitmidicom_'+curr_search_term+'.mid'))\n",
    "    print('a done')\n",
    "    b=freemidiorg(searched_artist = curr_art, searched_song = curr_song, download_path_mp3code=(download_path+'freemidiorg_'+curr_search_term+'.mid'))\n",
    "    print('b done')\n",
    "    c=midiworldcom(searched_artist = curr_art, searched_song = curr_song,download_path_mp3code=(download_path+'midiworld_'+curr_search_term+'.mid'))\n",
    "    print('c done')\n",
    "    d=midisfreecom(search_term = curr_search_term,download_path_mp3code=(download_path+'midisfreecom_'+curr_mp3+'.mid'))\n",
    "    print('the midisfreedownloadcounter.com', midisfreecom_download_counter)\n",
    "    print('d done')\n",
    "    e=cpratocom(search_term = curr_search_term,download_path_mp3code=(download_path+'cpratocom_'+curr_mp3+'.mid'))\n",
    "    print('e done')\n",
    "    f=partnersinrhymecom(searched_artist = curr_art,searched_song=curr_song,download_path_mp3code=(download_path+'partnersinrhymecom_'+curr_search_term+'.mid'))\n",
    "    print('f done')\n",
    "    g=mididbcom(searched_artist = curr_art,searched_song=curr_song,download_path_mp3code=(download_path+'mididbcom_'+curr_search_term+'.mid'))   \n",
    "    print('g done')\n",
    "\n",
    "    h=miditunecom(searched_artist=curr_art, searched_song=curr_song, download_path_mp3code= (download_path+'miditunecom_'+curr_search_term+'.mid'))   \n",
    "    print('h done')\n",
    "    \n",
    "    # seems to be knocked out:\n",
    "    # when the webpage metalmidigrahamdowney.com works again you can activate it\n",
    "    #i=metalmidigrahamdowneycom(searched_artist = curr_art,searched_song=curr_song,download_path_mp3code=(download_path+'metalmidigrahamdowneycom_'+curr_search_term+'.mid'))    \n",
    "    print('i done')\n",
    "    non2k_path = download_path.replace('full','?')\n",
    "    j=nonstop2kcom(search_term = curr_search_term,download_path_mp3code=(non2k_path+'nonstop2kcom_'+curr_search_term+'.mid'))\n",
    "    print('j done')\n",
    "    \n",
    "    k = rppmfcom(searched_artist = curr_art,searched_song=curr_song,download_path_mp3code=(download_path+'rppmfcom_'+curr_search_term+'.mid'))    \n",
    "    print('k done')\n",
    "    \n",
    "    # l = kunstderfugecom(searched_artist=curr_art, searched_song=curr_song, download_path_mp3code=(download_path+'kunstderfugecom_'+curr_search_term+'.mid'))\n",
    "    # page wasn't standardized enough. So automatic downloading did not work out.\n",
    "    l = 5\n",
    "    print('l done')\n",
    "    \n",
    "    return_list = [a,b,c,d,e,f,g,h,j,k,l]#,i,j,k,l]\n",
    "    if -1 in return_list:\n",
    "        with open('index where stopped','w') as g:\n",
    "            g.write(f'{ind}, have a look to the other generated files.')\n",
    "    \n",
    "    # checking if we found files for search term in internet:\n",
    "    if day_limit_counter == day_limit_counter_old: # we downloaded nothing for a certain song\n",
    "        with open('final_missing_titles','a') as f:\n",
    "            f.write(f'{curr_search_term2} {curr_mp3}\\n') # getting file with all songs for which we have to find something\n",
    "    else:\n",
    "        with open('found_titles','a') as f:\n",
    "            f.write(f'{curr_search_term2} {curr_mp3}\\n')        \n",
    "    print(ind, '-th row/song_artist done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing found and unfound titles:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('found_titles', 'r') as found_songs:\n",
    "\n",
    "    content = found_songs.read()\n",
    "    \n",
    "    with open('no results for song', 'r') as not_found:\n",
    "\n",
    "        for line in not_found:\n",
    "            \n",
    "            if line.strip() not in content:\n",
    "                with open('final_missing_titles', 'a') as final:\n",
    "                    final.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Later info from 30.07.22: Finally, have a look at final_missing_titles to open kunstderfuge.com and download all needed classic songs.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
